{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MicroGrad demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd.engine import Value\n",
    "from micrograd.nn import Neuron, Layer, MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22ba00587c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make up a dataset\n",
    "\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "X, y = make_moons(n_samples=100, noise=0.1)\n",
    "\n",
    "y = y*2 - 1 # make y be -1 or 1\n",
    "# visualize in 2D\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=20, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP of [Layer 'l0' of [TanhNeuron(2), TanhNeuron(2), TanhNeuron(2)], Layer 'l1' of [TanhNeuron(3), TanhNeuron(3), TanhNeuron(3)], Layer 'l2' of [TanhNeuron(3), TanhNeuron(3), TanhNeuron(3)], Layer 'l3' of [TanhNeuron(3), TanhNeuron(3), TanhNeuron(3)], Layer 'l4' of [LinearNeuron(3)]]\n",
      "number of parameters 62\n"
     ]
    }
   ],
   "source": [
    "# initialize a model \n",
    "np.random.seed(1337)\n",
    "random.seed(1337)\n",
    "model = MLP(2, [3,3,3,3,1]) # 1-layer neural network\n",
    "print(model)\n",
    "print(\"number of parameters\", len(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+:(data=0.99439, grad=0.00000) 0.78\n"
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "def loss(batch_size=None):\n",
    "    \n",
    "    # inline DataLoader :)\n",
    "    if batch_size is None:\n",
    "        Xb, yb = X, y\n",
    "    else:\n",
    "        ri = np.random.permutation(X.shape[0])[:batch_size]\n",
    "        Xb, yb = X[ri], y[ri]\n",
    "    inputs = [list(map(Value, map(float,xrow))) for xrow in Xb]\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    \n",
    "    # svm \"max-margin\" loss\n",
    "    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(yb, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)\n",
    "\n",
    "total_loss, acc = loss()\n",
    "print(total_loss, acc)\n",
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize decision boundary\n",
    "def visualizeBoundary():\n",
    "    h = 0.05\n",
    "    x_min, x_max = X[:, 0].min() - 2, X[:, 0].max() + 2\n",
    "    y_min, y_max = X[:, 1].min() - 2, X[:, 1].max() + 2\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                        np.arange(y_min, y_max, h))\n",
    "    Xmesh = np.c_[xx.ravel(), yy.ravel()]\n",
    "    inputs = [list(map(Value, xrow)) for xrow in Xmesh]\n",
    "    scores = list(map(model, inputs))\n",
    "    Z = np.array([s.data > 0 for s in scores])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 learning rate: 0.62097 loss: 0.22817, accuracy: 90.0%, max_grad: -0.47110, max_grad_neuron: l0n2b, max_grad_data: -0.08677041456027457, sgn switches: 47\n",
      "step 1 learning rate: 0.42984 loss: 0.33752, accuracy: 83.0%, max_grad: 0.60271, max_grad_neuron: l0n2w0, max_grad_data: -0.39969725014072655, sgn switches: 46\n",
      "step 2 learning rate: 0.45185 loss: 0.28708, accuracy: 87.0%, max_grad: 1.18221, max_grad_neuron: l0n2w0, max_grad_data: -0.724805278833281, sgn switches: 0\n",
      "step 3 learning rate: 0.41220 loss: 0.29350, accuracy: 85.0%, max_grad: -0.45428, max_grad_neuron: l0n2b, max_grad_data: -0.2988800000587716, sgn switches: 24\n",
      "step 4 learning rate: 0.36150 loss: 0.27947, accuracy: 86.0%, max_grad: 0.13010, max_grad_neuron: l0n2b, max_grad_data: -0.3078241727022077, sgn switches: 31\n",
      "step 5 learning rate: 0.34637 loss: 0.27585, accuracy: 87.0%, max_grad: -0.10702, max_grad_neuron: l0n2w0, max_grad_data: -0.7185460528815347, sgn switches: 11\n",
      "step 6 learning rate: 0.32011 loss: 0.27349, accuracy: 87.0%, max_grad: -0.06747, max_grad_neuron: l0n2w0, max_grad_data: -0.7061981907458686, sgn switches: 18\n",
      "step 7 learning rate: 0.32456 loss: 0.27257, accuracy: 87.0%, max_grad: -0.08388, max_grad_neuron: l0n2b, max_grad_data: -0.3123472690482068, sgn switches: 7\n",
      "step 8 learning rate: 0.31656 loss: 0.27029, accuracy: 87.0%, max_grad: -0.23624, max_grad_neuron: l0n2b, max_grad_data: -0.30153844673246205, sgn switches: 8\n",
      "step 9 learning rate: 0.31011 loss: 0.25498, accuracy: 88.0%, max_grad: -0.32840, max_grad_neuron: l0n2b, max_grad_data: -0.2850106480715664, sgn switches: 12\n",
      "step 10 learning rate: 0.29658 loss: 0.25362, accuracy: 88.0%, max_grad: 0.19320, max_grad_neuron: l0n2w0, max_grad_data: -0.6660746234641048, sgn switches: 10\n",
      "step 11 learning rate: 0.29648 loss: 0.25081, accuracy: 88.0%, max_grad: 0.01103, max_grad_neuron: l0n2w0, max_grad_data: -0.667552239959582, sgn switches: 14\n",
      "step 12 learning rate: 0.29425 loss: 0.25077, accuracy: 88.0%, max_grad: 0.00450, max_grad_neuron: l0n2b, max_grad_data: -0.2822770306449902, sgn switches: 10\n",
      "step 13 learning rate: 0.30082 loss: 0.25075, accuracy: 88.0%, max_grad: -0.00441, max_grad_neuron: l4n0s, max_grad_data: 2.4302141277726665, sgn switches: 4\n",
      "step 14 learning rate: 0.30961 loss: 0.25072, accuracy: 88.0%, max_grad: -0.00437, max_grad_neuron: l4n0s, max_grad_data: 2.434580943851599, sgn switches: 1\n",
      "step 15 learning rate: 0.31961 loss: 0.25069, accuracy: 88.0%, max_grad: -0.00433, max_grad_neuron: l4n0s, max_grad_data: 2.438907131814007, sgn switches: 0\n",
      "step 16 learning rate: 0.32974 loss: 0.25066, accuracy: 88.0%, max_grad: -0.00429, max_grad_neuron: l4n0s, max_grad_data: 2.4431936661394547, sgn switches: 1\n",
      "step 17 learning rate: 0.34175 loss: 0.25063, accuracy: 88.0%, max_grad: -0.00425, max_grad_neuron: l4n0s, max_grad_data: 2.4474415172758044, sgn switches: 0\n",
      "step 18 learning rate: 0.35495 loss: 0.25060, accuracy: 88.0%, max_grad: -0.00421, max_grad_neuron: l4n0s, max_grad_data: 2.451651650978392, sgn switches: 0\n",
      "step 19 learning rate: 0.36896 loss: 0.25057, accuracy: 88.0%, max_grad: -0.00417, max_grad_neuron: l4n0s, max_grad_data: 2.4558250267313118, sgn switches: 1\n",
      "step 20 learning rate: 0.38431 loss: 0.25054, accuracy: 88.0%, max_grad: -0.00414, max_grad_neuron: l4n0s, max_grad_data: 2.4599625980944957, sgn switches: 1\n",
      "step 21 learning rate: 0.40177 loss: 0.25050, accuracy: 88.0%, max_grad: -0.00410, max_grad_neuron: l4n0s, max_grad_data: 2.4640653145410125, sgn switches: 0\n",
      "step 22 learning rate: 0.42098 loss: 0.25047, accuracy: 88.0%, max_grad: -0.00407, max_grad_neuron: l4n0s, max_grad_data: 2.468134124694951, sgn switches: 0\n",
      "step 23 learning rate: 0.44211 loss: 0.25043, accuracy: 88.0%, max_grad: -0.00404, max_grad_neuron: l4n0s, max_grad_data: 2.472169980177516, sgn switches: 0\n",
      "step 24 learning rate: 0.46310 loss: 0.25040, accuracy: 88.0%, max_grad: -0.00400, max_grad_neuron: l4n0s, max_grad_data: 2.476173839548784, sgn switches: 0\n",
      "step 25 learning rate: 0.47553 loss: 0.25036, accuracy: 88.0%, max_grad: -0.00397, max_grad_neuron: l4n0s, max_grad_data: 2.480146658703004, sgn switches: 0\n",
      "step 26 learning rate: 0.48922 loss: 0.25032, accuracy: 88.0%, max_grad: -0.00394, max_grad_neuron: l4n0s, max_grad_data: 2.4840893442944045, sgn switches: 0\n",
      "step 27 learning rate: 0.50427 loss: 0.25028, accuracy: 88.0%, max_grad: -0.00391, max_grad_neuron: l4n0s, max_grad_data: 2.4880028091479764, sgn switches: 0\n",
      "step 28 learning rate: 0.52082 loss: 0.25024, accuracy: 88.0%, max_grad: -0.00389, max_grad_neuron: l4n0s, max_grad_data: 2.4918879857120944, sgn switches: 0\n",
      "step 29 learning rate: 0.53904 loss: 0.25019, accuracy: 88.0%, max_grad: -0.00386, max_grad_neuron: l4n0s, max_grad_data: 2.4957458232039413, sgn switches: 0\n",
      "step 30 learning rate: 0.55907 loss: 0.25015, accuracy: 88.0%, max_grad: -0.00383, max_grad_neuron: l4n0s, max_grad_data: 2.4995772927835884, sgn switches: 0\n",
      "step 31 learning rate: 0.58110 loss: 0.25010, accuracy: 88.0%, max_grad: -0.00381, max_grad_neuron: l4n0s, max_grad_data: 2.5033833873979376, sgn switches: 0\n",
      "step 32 learning rate: 0.60534 loss: 0.25005, accuracy: 88.0%, max_grad: -0.00378, max_grad_neuron: l4n0s, max_grad_data: 2.5071651263492374, sgn switches: 0\n",
      "step 33 learning rate: 0.62762 loss: 0.25000, accuracy: 88.0%, max_grad: -0.00376, max_grad_neuron: l4n0s, max_grad_data: 2.510923554259232, sgn switches: 0\n",
      "step 34 learning rate: 0.64875 loss: 0.24995, accuracy: 88.0%, max_grad: -0.00374, max_grad_neuron: l4n0s, max_grad_data: 2.5146597402048427, sgn switches: 0\n",
      "step 35 learning rate: 0.67169 loss: 0.24990, accuracy: 88.0%, max_grad: -0.00371, max_grad_neuron: l4n0s, max_grad_data: 2.518374213420539, sgn switches: 0\n",
      "step 36 learning rate: 0.69693 loss: 0.24984, accuracy: 88.0%, max_grad: -0.00369, max_grad_neuron: l4n0s, max_grad_data: 2.5220674359501, sgn switches: 0\n",
      "step 37 learning rate: 0.72468 loss: 0.24979, accuracy: 88.0%, max_grad: -0.00367, max_grad_neuron: l4n0s, max_grad_data: 2.5257399011512947, sgn switches: 0\n",
      "step 38 learning rate: 0.75522 loss: 0.24973, accuracy: 88.0%, max_grad: -0.00365, max_grad_neuron: l4n0s, max_grad_data: 2.529392050088029, sgn switches: 0\n",
      "step 39 learning rate: 0.78880 loss: 0.24967, accuracy: 88.0%, max_grad: -0.00363, max_grad_neuron: l4n0s, max_grad_data: 2.533024496596594, sgn switches: 0\n",
      "step 40 learning rate: 0.82224 loss: 0.24961, accuracy: 88.0%, max_grad: -0.00361, max_grad_neuron: l4n0s, max_grad_data: 2.5366372818228653, sgn switches: 2\n",
      "step 41 learning rate: 0.81406 loss: 0.24954, accuracy: 88.0%, max_grad: -0.00371, max_grad_neuron: l0n2w1, max_grad_data: 2.226662062945335, sgn switches: 8\n",
      "step 42 learning rate: 0.75509 loss: 0.24949, accuracy: 88.0%, max_grad: 0.01002, max_grad_neuron: l0n2b, max_grad_data: -0.2905607927352411, sgn switches: 18\n",
      "step 43 learning rate: 0.69206 loss: 0.24950, accuracy: 88.0%, max_grad: -0.03351, max_grad_neuron: l0n2w0, max_grad_data: -0.6732797207968927, sgn switches: 23\n",
      "step 44 learning rate: 0.65262 loss: 0.24951, accuracy: 88.0%, max_grad: 0.04509, max_grad_neuron: l0n2w0, max_grad_data: -0.6792689792931066, sgn switches: 24\n",
      "step 45 learning rate: 0.64260 loss: 0.24932, accuracy: 88.0%, max_grad: 0.00659, max_grad_neuron: l0n2b, max_grad_data: -0.29056870626032905, sgn switches: 10\n",
      "step 46 learning rate: 0.64557 loss: 0.24927, accuracy: 88.0%, max_grad: 0.00649, max_grad_neuron: l0n2b, max_grad_data: -0.2907842056567749, sgn switches: 0\n",
      "step 47 learning rate: 0.64743 loss: 0.24923, accuracy: 88.0%, max_grad: 0.00602, max_grad_neuron: l0n2b, max_grad_data: -0.2910042350838049, sgn switches: 2\n",
      "step 48 learning rate: 0.65088 loss: 0.24918, accuracy: 88.0%, max_grad: 0.00545, max_grad_neuron: l0n2b, max_grad_data: -0.2912232685561406, sgn switches: 0\n",
      "step 49 learning rate: 0.65451 loss: 0.24913, accuracy: 88.0%, max_grad: 0.00489, max_grad_neuron: l0n2b, max_grad_data: -0.2914395304907063, sgn switches: 1\n",
      "step 50 learning rate: 0.65868 loss: 0.24909, accuracy: 88.0%, max_grad: 0.00438, max_grad_neuron: l0n2b, max_grad_data: -0.29165232753798437, sgn switches: 0\n",
      "step 51 learning rate: 0.66325 loss: 0.24904, accuracy: 88.0%, max_grad: 0.00392, max_grad_neuron: l0n2b, max_grad_data: -0.2918618753045025, sgn switches: 0\n",
      "step 52 learning rate: 0.66725 loss: 0.24900, accuracy: 88.0%, max_grad: 0.00352, max_grad_neuron: l0n2b, max_grad_data: -0.2920690499385348, sgn switches: 2\n",
      "step 53 learning rate: 0.67269 loss: 0.24896, accuracy: 88.0%, max_grad: -0.00337, max_grad_neuron: l4n0s, max_grad_data: 2.5818896038857706, sgn switches: 0\n",
      "step 54 learning rate: 0.67804 loss: 0.24892, accuracy: 88.0%, max_grad: -0.00335, max_grad_neuron: l4n0s, max_grad_data: 2.585241731168302, sgn switches: 1\n",
      "step 55 learning rate: 0.68455 loss: 0.24888, accuracy: 88.0%, max_grad: -0.00333, max_grad_neuron: l4n0s, max_grad_data: 2.588575859152022, sgn switches: 0\n",
      "step 56 learning rate: 0.69172 loss: 0.24883, accuracy: 88.0%, max_grad: -0.00332, max_grad_neuron: l4n0s, max_grad_data: 2.591892086295187, sgn switches: 0\n",
      "step 57 learning rate: 0.69877 loss: 0.24879, accuracy: 88.0%, max_grad: -0.00330, max_grad_neuron: l4n0s, max_grad_data: 2.595190510351147, sgn switches: 1\n",
      "step 58 learning rate: 0.70735 loss: 0.24876, accuracy: 88.0%, max_grad: -0.00328, max_grad_neuron: l4n0s, max_grad_data: 2.598471229312256, sgn switches: 0\n",
      "step 59 learning rate: 0.71465 loss: 0.24872, accuracy: 88.0%, max_grad: -0.00326, max_grad_neuron: l4n0s, max_grad_data: 2.6017343418279357, sgn switches: 0\n",
      "step 60 learning rate: 0.71928 loss: 0.24868, accuracy: 88.0%, max_grad: -0.00325, max_grad_neuron: l4n0s, max_grad_data: 2.6049799453214937, sgn switches: 0\n",
      "step 61 learning rate: 0.72346 loss: 0.24864, accuracy: 88.0%, max_grad: -0.00323, max_grad_neuron: l4n0s, max_grad_data: 2.6082081377900708, sgn switches: 0\n",
      "step 62 learning rate: 0.72807 loss: 0.24860, accuracy: 88.0%, max_grad: -0.00321, max_grad_neuron: l4n0s, max_grad_data: 2.6114190202591283, sgn switches: 0\n",
      "step 63 learning rate: 0.73313 loss: 0.24857, accuracy: 88.0%, max_grad: -0.00319, max_grad_neuron: l4n0s, max_grad_data: 2.6146126935452028, sgn switches: 0\n",
      "step 64 learning rate: 0.73870 loss: 0.24853, accuracy: 88.0%, max_grad: -0.00318, max_grad_neuron: l4n0s, max_grad_data: 2.617789259662232, sgn switches: 0\n",
      "step 65 learning rate: 0.74483 loss: 0.24850, accuracy: 88.0%, max_grad: -0.00316, max_grad_neuron: l4n0s, max_grad_data: 2.6209488208198786, sgn switches: 0\n",
      "step 66 learning rate: 0.75086 loss: 0.24846, accuracy: 88.0%, max_grad: -0.00314, max_grad_neuron: l4n0s, max_grad_data: 2.6240914801196142, sgn switches: 1\n",
      "step 67 learning rate: 0.75741 loss: 0.24843, accuracy: 88.0%, max_grad: -0.00313, max_grad_neuron: l4n0s, max_grad_data: 2.627217340640393, sgn switches: 1\n",
      "step 68 learning rate: 0.76541 loss: 0.24839, accuracy: 88.0%, max_grad: -0.00311, max_grad_neuron: l4n0s, max_grad_data: 2.630326506515744, sgn switches: 0\n",
      "step 69 learning rate: 0.77421 loss: 0.24836, accuracy: 88.0%, max_grad: -0.00309, max_grad_neuron: l4n0s, max_grad_data: 2.6334190809561546, sgn switches: 0\n",
      "step 70 learning rate: 0.78389 loss: 0.24833, accuracy: 88.0%, max_grad: -0.00308, max_grad_neuron: l4n0s, max_grad_data: 2.636495169623391, sgn switches: 0\n",
      "step 71 learning rate: 0.79454 loss: 0.24829, accuracy: 88.0%, max_grad: -0.00306, max_grad_neuron: l4n0s, max_grad_data: 2.63955487320562, sgn switches: 0\n",
      "step 72 learning rate: 0.80625 loss: 0.24826, accuracy: 88.0%, max_grad: -0.00304, max_grad_neuron: l4n0s, max_grad_data: 2.6425983055479354, sgn switches: 0\n",
      "step 73 learning rate: 0.81913 loss: 0.24823, accuracy: 88.0%, max_grad: -0.00303, max_grad_neuron: l4n0s, max_grad_data: 2.6456255416551793, sgn switches: 0\n",
      "step 74 learning rate: 0.82909 loss: 0.24820, accuracy: 88.0%, max_grad: -0.00301, max_grad_neuron: l4n0s, max_grad_data: 2.6486367866136726, sgn switches: 1\n",
      "step 75 learning rate: 0.83331 loss: 0.24817, accuracy: 88.0%, max_grad: -0.00299, max_grad_neuron: l4n0s, max_grad_data: 2.6516317505426494, sgn switches: 3\n",
      "step 76 learning rate: 0.80727 loss: 0.24813, accuracy: 88.0%, max_grad: -0.00298, max_grad_neuron: l4n0s, max_grad_data: 2.654612405605236, sgn switches: 10\n",
      "step 77 learning rate: 0.74235 loss: 0.24811, accuracy: 88.0%, max_grad: 0.00914, max_grad_neuron: l0n2w0, max_grad_data: -0.6874771711747133, sgn switches: 20\n",
      "step 78 learning rate: 0.71005 loss: 0.24808, accuracy: 88.0%, max_grad: -0.00311, max_grad_neuron: l0n2w1, max_grad_data: 2.2535066992865316, sgn switches: 20\n",
      "step 79 learning rate: 0.70927 loss: 0.24805, accuracy: 88.0%, max_grad: -0.00293, max_grad_neuron: l4n0s, max_grad_data: 2.663452942248736, sgn switches: 10\n",
      "step 80 learning rate: 0.70839 loss: 0.24803, accuracy: 88.0%, max_grad: -0.00292, max_grad_neuron: l4n0s, max_grad_data: 2.6663686182579243, sgn switches: 3\n",
      "step 81 learning rate: 0.71072 loss: 0.24800, accuracy: 88.0%, max_grad: 0.00316, max_grad_neuron: l0n2b, max_grad_data: -0.2997475693735943, sgn switches: 1\n",
      "step 82 learning rate: 0.71320 loss: 0.24798, accuracy: 88.0%, max_grad: 0.00334, max_grad_neuron: l0n2b, max_grad_data: -0.2998937989146551, sgn switches: 1\n",
      "step 83 learning rate: 0.71678 loss: 0.24795, accuracy: 88.0%, max_grad: 0.00335, max_grad_neuron: l0n2b, max_grad_data: -0.3000553057710172, sgn switches: 0\n",
      "step 84 learning rate: 0.71265 loss: 0.24793, accuracy: 88.0%, max_grad: 0.00327, max_grad_neuron: l0n2b, max_grad_data: -0.3002289477841561, sgn switches: 1\n",
      "step 85 learning rate: 0.71778 loss: 0.24791, accuracy: 88.0%, max_grad: 0.00315, max_grad_neuron: l0n2b, max_grad_data: -0.30041276189241967, sgn switches: 0\n",
      "step 86 learning rate: 0.72287 loss: 0.24789, accuracy: 88.0%, max_grad: 0.00300, max_grad_neuron: l0n2b, max_grad_data: -0.30060553242466825, sgn switches: 1\n",
      "step 87 learning rate: 0.72841 loss: 0.24786, accuracy: 88.0%, max_grad: 0.00285, max_grad_neuron: l0n2b, max_grad_data: -0.30080657911464204, sgn switches: 1\n",
      "step 88 learning rate: 0.73512 loss: 0.24784, accuracy: 88.0%, max_grad: -0.00279, max_grad_neuron: l4n0s, max_grad_data: 2.68914222412197, sgn switches: 0\n",
      "step 89 learning rate: 0.74250 loss: 0.24782, accuracy: 88.0%, max_grad: -0.00278, max_grad_neuron: l4n0s, max_grad_data: 2.6919219504473193, sgn switches: 0\n",
      "step 90 learning rate: 0.74979 loss: 0.24780, accuracy: 88.0%, max_grad: -0.00277, max_grad_neuron: l4n0s, max_grad_data: 2.694687158571963, sgn switches: 1\n",
      "step 91 learning rate: 0.75864 loss: 0.24778, accuracy: 88.0%, max_grad: -0.00275, max_grad_neuron: l4n0s, max_grad_data: 2.6974379550503955, sgn switches: 0\n",
      "step 92 learning rate: 0.76722 loss: 0.24775, accuracy: 88.0%, max_grad: -0.00274, max_grad_neuron: l4n0s, max_grad_data: 2.7001744457862484, sgn switches: 0\n",
      "step 93 learning rate: 0.77334 loss: 0.24773, accuracy: 88.0%, max_grad: -0.00272, max_grad_neuron: l4n0s, max_grad_data: 2.702896735838855, sgn switches: 0\n",
      "step 94 learning rate: 0.77648 loss: 0.24771, accuracy: 88.0%, max_grad: -0.00271, max_grad_neuron: l4n0s, max_grad_data: 2.7056049718586497, sgn switches: 0\n",
      "step 95 learning rate: 0.77861 loss: 0.24769, accuracy: 88.0%, max_grad: -0.00269, max_grad_neuron: l4n0s, max_grad_data: 2.708299267368955, sgn switches: 1\n",
      "step 96 learning rate: 0.78228 loss: 0.24767, accuracy: 88.0%, max_grad: -0.00268, max_grad_neuron: l4n0s, max_grad_data: 2.710979707061428, sgn switches: 0\n",
      "step 97 learning rate: 0.78631 loss: 0.24765, accuracy: 88.0%, max_grad: -0.00267, max_grad_neuron: l4n0s, max_grad_data: 2.7136464047747126, sgn switches: 0\n",
      "step 98 learning rate: 0.79075 loss: 0.24763, accuracy: 88.0%, max_grad: -0.00265, max_grad_neuron: l4n0s, max_grad_data: 2.7162994356914023, sgn switches: 0\n",
      "step 99 learning rate: 0.79563 loss: 0.24761, accuracy: 88.0%, max_grad: -0.00264, max_grad_neuron: l4n0s, max_grad_data: 2.718938924607384, sgn switches: 0\n",
      "step 100 learning rate: 0.80100 loss: 0.24759, accuracy: 88.0%, max_grad: -0.00263, max_grad_neuron: l4n0s, max_grad_data: 2.721564918537169, sgn switches: 0\n",
      "step 101 learning rate: 0.80662 loss: 0.24757, accuracy: 88.0%, max_grad: -0.00261, max_grad_neuron: l4n0s, max_grad_data: 2.7241775913365895, sgn switches: 0\n",
      "step 102 learning rate: 0.81148 loss: 0.24755, accuracy: 88.0%, max_grad: -0.00260, max_grad_neuron: l4n0s, max_grad_data: 2.726776879020847, sgn switches: 0\n",
      "step 103 learning rate: 0.81508 loss: 0.24753, accuracy: 88.0%, max_grad: -0.00259, max_grad_neuron: l4n0s, max_grad_data: 2.7293632016410596, sgn switches: 2\n",
      "step 104 learning rate: 0.81992 loss: 0.24752, accuracy: 88.0%, max_grad: -0.00257, max_grad_neuron: l4n0s, max_grad_data: 2.731935877893068, sgn switches: 2\n",
      "step 105 learning rate: 0.79480 loss: 0.24750, accuracy: 88.0%, max_grad: -0.00256, max_grad_neuron: l4n0s, max_grad_data: 2.7344969805826285, sgn switches: 11\n",
      "step 106 learning rate: 0.74460 loss: 0.24748, accuracy: 88.0%, max_grad: 0.00617, max_grad_neuron: l0n2w0, max_grad_data: -0.6944925127091808, sgn switches: 19\n",
      "step 107 learning rate: 0.72780 loss: 0.24746, accuracy: 88.0%, max_grad: -0.00253, max_grad_neuron: l4n0s, max_grad_data: 2.739575797004751, sgn switches: 8\n",
      "step 108 learning rate: 0.73122 loss: 0.24745, accuracy: 88.0%, max_grad: -0.00252, max_grad_neuron: l4n0s, max_grad_data: 2.742096982745926, sgn switches: 0\n",
      "step 109 learning rate: 0.73499 loss: 0.24743, accuracy: 88.0%, max_grad: -0.00251, max_grad_neuron: l4n0s, max_grad_data: 2.744605444059973, sgn switches: 0\n",
      "step 110 learning rate: 0.73914 loss: 0.24742, accuracy: 88.0%, max_grad: -0.00250, max_grad_neuron: l4n0s, max_grad_data: 2.747101277898809, sgn switches: 0\n",
      "step 111 learning rate: 0.74369 loss: 0.24740, accuracy: 88.0%, max_grad: -0.00248, max_grad_neuron: l4n0s, max_grad_data: 2.7495845798416396, sgn switches: 0\n",
      "step 112 learning rate: 0.74871 loss: 0.24739, accuracy: 88.0%, max_grad: -0.00247, max_grad_neuron: l4n0s, max_grad_data: 2.7520554443571728, sgn switches: 0\n",
      "step 113 learning rate: 0.75422 loss: 0.24737, accuracy: 88.0%, max_grad: -0.00246, max_grad_neuron: l4n0s, max_grad_data: 2.7545139650074315, sgn switches: 0\n",
      "step 114 learning rate: 0.76029 loss: 0.24736, accuracy: 88.0%, max_grad: -0.00245, max_grad_neuron: l4n0s, max_grad_data: 2.756960234540495, sgn switches: 0\n",
      "step 115 learning rate: 0.76697 loss: 0.24734, accuracy: 88.0%, max_grad: -0.00243, max_grad_neuron: l4n0s, max_grad_data: 2.7593943449179417, sgn switches: 0\n",
      "step 116 learning rate: 0.77431 loss: 0.24733, accuracy: 88.0%, max_grad: -0.00242, max_grad_neuron: l4n0s, max_grad_data: 2.7618163873123374, sgn switches: 0\n",
      "step 117 learning rate: 0.78238 loss: 0.24731, accuracy: 88.0%, max_grad: -0.00241, max_grad_neuron: l4n0s, max_grad_data: 2.764226452099348, sgn switches: 0\n",
      "step 118 learning rate: 0.79072 loss: 0.24730, accuracy: 88.0%, max_grad: -0.00240, max_grad_neuron: l4n0s, max_grad_data: 2.7666246288490046, sgn switches: 2\n",
      "step 119 learning rate: 0.80043 loss: 0.24729, accuracy: 88.0%, max_grad: -0.00239, max_grad_neuron: l4n0s, max_grad_data: 2.7690110063435047, sgn switches: 0\n",
      "step 120 learning rate: 0.81112 loss: 0.24727, accuracy: 88.0%, max_grad: -0.00237, max_grad_neuron: l4n0s, max_grad_data: 2.7713856724986305, sgn switches: 0\n",
      "step 121 learning rate: 0.82216 loss: 0.24726, accuracy: 88.0%, max_grad: -0.00236, max_grad_neuron: l4n0s, max_grad_data: 2.7737487144771484, sgn switches: 0\n",
      "step 122 learning rate: 0.83055 loss: 0.24724, accuracy: 88.0%, max_grad: -0.00235, max_grad_neuron: l4n0s, max_grad_data: 2.7761002184165093, sgn switches: 0\n",
      "step 123 learning rate: 0.83619 loss: 0.24723, accuracy: 88.0%, max_grad: -0.00234, max_grad_neuron: l4n0s, max_grad_data: 2.7784403179367576, sgn switches: 0\n",
      "step 124 learning rate: 0.84239 loss: 0.24722, accuracy: 88.0%, max_grad: -0.00233, max_grad_neuron: l4n0s, max_grad_data: 2.7807689947995495, sgn switches: 0\n",
      "step 125 learning rate: 0.84150 loss: 0.24720, accuracy: 88.0%, max_grad: -0.00232, max_grad_neuron: l4n0s, max_grad_data: 2.7830866731794566, sgn switches: 3\n",
      "step 126 learning rate: 0.82770 loss: 0.24719, accuracy: 88.0%, max_grad: 0.00302, max_grad_neuron: l0n2w0, max_grad_data: -0.7005389985887241, sgn switches: 7\n",
      "step 127 learning rate: 0.76322 loss: 0.24718, accuracy: 88.0%, max_grad: -0.01043, max_grad_neuron: l0n2w0, max_grad_data: -0.6974112831678038, sgn switches: 16\n",
      "step 128 learning rate: 0.68018 loss: 0.24721, accuracy: 88.0%, max_grad: 0.02482, max_grad_neuron: l0n2w0, max_grad_data: -0.7011337463674309, sgn switches: 25\n",
      "step 129 learning rate: 0.63880 loss: 0.24716, accuracy: 88.0%, max_grad: -0.01073, max_grad_neuron: l0n2w0, max_grad_data: -0.7003288974004945, sgn switches: 25\n",
      "step 130 learning rate: 0.63570 loss: 0.24714, accuracy: 88.0%, max_grad: -0.00226, max_grad_neuron: l4n0s, max_grad_data: 2.794504343905317, sgn switches: 12\n",
      "step 131 learning rate: 0.63587 loss: 0.24713, accuracy: 88.0%, max_grad: 0.00243, max_grad_neuron: l0n2b, max_grad_data: -0.31076002183228885, sgn switches: 4\n",
      "step 132 learning rate: 0.63885 loss: 0.24712, accuracy: 88.0%, max_grad: 0.00251, max_grad_neuron: l0n2b, max_grad_data: -0.3108738655561993, sgn switches: 2\n",
      "step 133 learning rate: 0.64305 loss: 0.24711, accuracy: 88.0%, max_grad: 0.00248, max_grad_neuron: l0n2b, max_grad_data: -0.31099781232886725, sgn switches: 0\n",
      "step 134 learning rate: 0.64720 loss: 0.24710, accuracy: 88.0%, max_grad: 0.00240, max_grad_neuron: l0n2b, max_grad_data: -0.31112962581054016, sgn switches: 1\n",
      "step 135 learning rate: 0.65224 loss: 0.24709, accuracy: 88.0%, max_grad: 0.00229, max_grad_neuron: l0n2b, max_grad_data: -0.31126794665920743, sgn switches: 0\n",
      "step 136 learning rate: 0.65779 loss: 0.24708, accuracy: 88.0%, max_grad: -0.00220, max_grad_neuron: l4n0s, max_grad_data: 2.807847521206067, sgn switches: 0\n",
      "step 137 learning rate: 0.66389 loss: 0.24707, accuracy: 88.0%, max_grad: -0.00219, max_grad_neuron: l4n0s, max_grad_data: 2.8100345252602827, sgn switches: 0\n",
      "step 138 learning rate: 0.66989 loss: 0.24706, accuracy: 88.0%, max_grad: -0.00218, max_grad_neuron: l4n0s, max_grad_data: 2.812211236598193, sgn switches: 1\n",
      "step 139 learning rate: 0.67720 loss: 0.24705, accuracy: 88.0%, max_grad: -0.00217, max_grad_neuron: l4n0s, max_grad_data: 2.8143777321091674, sgn switches: 0\n",
      "step 140 learning rate: 0.68525 loss: 0.24704, accuracy: 88.0%, max_grad: -0.00216, max_grad_neuron: l4n0s, max_grad_data: 2.8165340875663483, sgn switches: 0\n",
      "step 141 learning rate: 0.69409 loss: 0.24703, accuracy: 88.0%, max_grad: -0.00215, max_grad_neuron: l4n0s, max_grad_data: 2.8186803777248945, sgn switches: 0\n",
      "step 142 learning rate: 0.70279 loss: 0.24702, accuracy: 88.0%, max_grad: -0.00214, max_grad_neuron: l4n0s, max_grad_data: 2.82081667641025, sgn switches: 1\n",
      "step 143 learning rate: 0.71339 loss: 0.24701, accuracy: 88.0%, max_grad: -0.00213, max_grad_neuron: l4n0s, max_grad_data: 2.822943056626506, sgn switches: 0\n",
      "step 144 learning rate: 0.72148 loss: 0.24700, accuracy: 88.0%, max_grad: -0.00212, max_grad_neuron: l4n0s, max_grad_data: 2.825059590633785, sgn switches: 0\n",
      "step 145 learning rate: 0.72589 loss: 0.24699, accuracy: 88.0%, max_grad: -0.00211, max_grad_neuron: l4n0s, max_grad_data: 2.8271663744381734, sgn switches: 0\n",
      "step 146 learning rate: 0.73073 loss: 0.24698, accuracy: 88.0%, max_grad: -0.00210, max_grad_neuron: l4n0s, max_grad_data: 2.82926348705871, sgn switches: 0\n",
      "step 147 learning rate: 0.73606 loss: 0.24697, accuracy: 88.0%, max_grad: -0.00209, max_grad_neuron: l4n0s, max_grad_data: 2.83135099055293, sgn switches: 0\n",
      "step 148 learning rate: 0.74193 loss: 0.24696, accuracy: 88.0%, max_grad: -0.00208, max_grad_neuron: l4n0s, max_grad_data: 2.8334289628526315, sgn switches: 0\n",
      "step 149 learning rate: 0.74838 loss: 0.24695, accuracy: 88.0%, max_grad: -0.00207, max_grad_neuron: l4n0s, max_grad_data: 2.835497459031316, sgn switches: 0\n",
      "step 150 learning rate: 0.75548 loss: 0.24694, accuracy: 88.0%, max_grad: -0.00206, max_grad_neuron: l4n0s, max_grad_data: 2.8375565642914258, sgn switches: 0\n",
      "step 151 learning rate: 0.76328 loss: 0.24693, accuracy: 88.0%, max_grad: -0.00205, max_grad_neuron: l4n0s, max_grad_data: 2.839606313444027, sgn switches: 0\n",
      "step 152 learning rate: 0.77187 loss: 0.24692, accuracy: 88.0%, max_grad: -0.00204, max_grad_neuron: l4n0s, max_grad_data: 2.8416468288255605, sgn switches: 0\n",
      "step 153 learning rate: 0.78131 loss: 0.24691, accuracy: 88.0%, max_grad: -0.00203, max_grad_neuron: l4n0s, max_grad_data: 2.843678055789431, sgn switches: 0\n",
      "step 154 learning rate: 0.78925 loss: 0.24690, accuracy: 88.0%, max_grad: -0.00202, max_grad_neuron: l4n0s, max_grad_data: 2.8457003309904683, sgn switches: 3\n",
      "step 155 learning rate: 0.79266 loss: 0.24689, accuracy: 88.0%, max_grad: -0.00201, max_grad_neuron: l4n0s, max_grad_data: 2.8477130174582417, sgn switches: 4\n",
      "step 156 learning rate: 0.77200 loss: 0.24688, accuracy: 88.0%, max_grad: -0.00286, max_grad_neuron: l0n2w0, max_grad_data: -0.7042949392879867, sgn switches: 12\n",
      "step 157 learning rate: 0.73613 loss: 0.24688, accuracy: 88.0%, max_grad: 0.00673, max_grad_neuron: l0n2w0, max_grad_data: -0.7049786873600473, sgn switches: 17\n",
      "step 158 learning rate: 0.72693 loss: 0.24687, accuracy: 88.0%, max_grad: -0.00199, max_grad_neuron: l4n0s, max_grad_data: 2.853697216046168, sgn switches: 8\n",
      "step 159 learning rate: 0.73462 loss: 0.24686, accuracy: 88.0%, max_grad: -0.00198, max_grad_neuron: l4n0s, max_grad_data: 2.8556742811839886, sgn switches: 1\n",
      "step 160 learning rate: 0.73915 loss: 0.24685, accuracy: 88.0%, max_grad: -0.00197, max_grad_neuron: l4n0s, max_grad_data: 2.857642422510344, sgn switches: 1\n",
      "step 161 learning rate: 0.74371 loss: 0.24684, accuracy: 88.0%, max_grad: -0.00196, max_grad_neuron: l4n0s, max_grad_data: 2.859601758147677, sgn switches: 0\n",
      "step 162 learning rate: 0.74818 loss: 0.24684, accuracy: 88.0%, max_grad: -0.00195, max_grad_neuron: l4n0s, max_grad_data: 2.8615523815879853, sgn switches: 1\n",
      "step 163 learning rate: 0.75364 loss: 0.24683, accuracy: 88.0%, max_grad: -0.00194, max_grad_neuron: l4n0s, max_grad_data: 2.8634943714102175, sgn switches: 0\n",
      "step 164 learning rate: 0.75934 loss: 0.24682, accuracy: 88.0%, max_grad: -0.00193, max_grad_neuron: l4n0s, max_grad_data: 2.865427797571844, sgn switches: 2\n",
      "step 165 learning rate: 0.76592 loss: 0.24681, accuracy: 88.0%, max_grad: -0.00192, max_grad_neuron: l4n0s, max_grad_data: 2.8673527251966724, sgn switches: 0\n",
      "step 166 learning rate: 0.77316 loss: 0.24681, accuracy: 88.0%, max_grad: -0.00192, max_grad_neuron: l4n0s, max_grad_data: 2.869269216629456, sgn switches: 0\n",
      "step 167 learning rate: 0.78011 loss: 0.24680, accuracy: 88.0%, max_grad: -0.00191, max_grad_neuron: l4n0s, max_grad_data: 2.8711773324964174, sgn switches: 0\n",
      "step 168 learning rate: 0.78715 loss: 0.24679, accuracy: 88.0%, max_grad: -0.00190, max_grad_neuron: l4n0s, max_grad_data: 2.873077132324105, sgn switches: 0\n",
      "step 169 learning rate: 0.79490 loss: 0.24679, accuracy: 88.0%, max_grad: -0.00189, max_grad_neuron: l4n0s, max_grad_data: 2.874968674857832, sgn switches: 0\n",
      "step 170 learning rate: 0.80260 loss: 0.24678, accuracy: 88.0%, max_grad: -0.00188, max_grad_neuron: l4n0s, max_grad_data: 2.8768520182216046, sgn switches: 1\n",
      "step 171 learning rate: 0.81099 loss: 0.24677, accuracy: 88.0%, max_grad: -0.00188, max_grad_neuron: l4n0s, max_grad_data: 2.878727220034536, sgn switches: 1\n",
      "step 172 learning rate: 0.82112 loss: 0.24676, accuracy: 88.0%, max_grad: -0.00187, max_grad_neuron: l4n0s, max_grad_data: 2.880594337487242, sgn switches: 0\n",
      "step 173 learning rate: 0.82969 loss: 0.24676, accuracy: 88.0%, max_grad: -0.00186, max_grad_neuron: l4n0s, max_grad_data: 2.882453427047752, sgn switches: 0\n",
      "step 174 learning rate: 0.83524 loss: 0.24675, accuracy: 88.0%, max_grad: -0.00185, max_grad_neuron: l4n0s, max_grad_data: 2.884304563012257, sgn switches: 0\n",
      "step 175 learning rate: 0.84134 loss: 0.24674, accuracy: 88.0%, max_grad: -0.00184, max_grad_neuron: l4n0s, max_grad_data: 2.886147805437153, sgn switches: 0\n",
      "step 176 learning rate: 0.84748 loss: 0.24674, accuracy: 88.0%, max_grad: -0.00184, max_grad_neuron: l4n0s, max_grad_data: 2.887983204298428, sgn switches: 0\n",
      "step 177 learning rate: 0.85320 loss: 0.24673, accuracy: 88.0%, max_grad: -0.00183, max_grad_neuron: l4n0s, max_grad_data: 2.8898108173957833, sgn switches: 0\n",
      "step 178 learning rate: 0.85949 loss: 0.24672, accuracy: 88.0%, max_grad: -0.00182, max_grad_neuron: l4n0s, max_grad_data: 2.8916306913716565, sgn switches: 0\n",
      "step 179 learning rate: 0.86515 loss: 0.24672, accuracy: 88.0%, max_grad: -0.00181, max_grad_neuron: l4n0s, max_grad_data: 2.893442888482484, sgn switches: 1\n",
      "step 180 learning rate: 0.87263 loss: 0.24671, accuracy: 88.0%, max_grad: -0.00180, max_grad_neuron: l4n0s, max_grad_data: 2.895247440620694, sgn switches: 0\n",
      "step 181 learning rate: 0.87205 loss: 0.24670, accuracy: 88.0%, max_grad: -0.00180, max_grad_neuron: l4n0s, max_grad_data: 2.897044442090091, sgn switches: 1\n",
      "step 182 learning rate: 0.87098 loss: 0.24670, accuracy: 88.0%, max_grad: -0.00179, max_grad_neuron: l4n0s, max_grad_data: 2.8988338342685513, sgn switches: 1\n",
      "step 183 learning rate: 0.85509 loss: 0.24669, accuracy: 88.0%, max_grad: -0.00178, max_grad_neuron: l4n0s, max_grad_data: 2.900615933417848, sgn switches: 4\n",
      "step 184 learning rate: 0.84384 loss: 0.24668, accuracy: 88.0%, max_grad: -0.00177, max_grad_neuron: l4n0s, max_grad_data: 2.902390102237854, sgn switches: 9\n",
      "step 185 learning rate: 0.83560 loss: 0.24668, accuracy: 88.0%, max_grad: -0.00177, max_grad_neuron: l4n0s, max_grad_data: 2.9041573843665933, sgn switches: 6\n",
      "step 186 learning rate: 0.81736 loss: 0.24667, accuracy: 88.0%, max_grad: 0.00269, max_grad_neuron: l0n2w0, max_grad_data: -0.7085983129314459, sgn switches: 8\n",
      "step 187 learning rate: 0.81187 loss: 0.24666, accuracy: 88.0%, max_grad: -0.00175, max_grad_neuron: l4n0s, max_grad_data: 2.9076687290098104, sgn switches: 6\n",
      "step 188 learning rate: 0.81718 loss: 0.24666, accuracy: 88.0%, max_grad: -0.00175, max_grad_neuron: l4n0s, max_grad_data: 2.909413811582169, sgn switches: 1\n",
      "step 189 learning rate: 0.82309 loss: 0.24665, accuracy: 88.0%, max_grad: -0.00174, max_grad_neuron: l4n0s, max_grad_data: 2.9111517030721474, sgn switches: 0\n",
      "step 190 learning rate: 0.82726 loss: 0.24665, accuracy: 88.0%, max_grad: -0.00173, max_grad_neuron: l4n0s, max_grad_data: 2.912882425589218, sgn switches: 0\n",
      "step 191 learning rate: 0.83096 loss: 0.24664, accuracy: 88.0%, max_grad: -0.00172, max_grad_neuron: l4n0s, max_grad_data: 2.9146060337158883, sgn switches: 0\n",
      "step 192 learning rate: 0.83502 loss: 0.24664, accuracy: 88.0%, max_grad: -0.00172, max_grad_neuron: l4n0s, max_grad_data: 2.916322571803327, sgn switches: 0\n",
      "step 193 learning rate: 0.83949 loss: 0.24663, accuracy: 88.0%, max_grad: -0.00171, max_grad_neuron: l4n0s, max_grad_data: 2.9180320901900645, sgn switches: 0\n",
      "step 194 learning rate: 0.84441 loss: 0.24662, accuracy: 88.0%, max_grad: -0.00170, max_grad_neuron: l4n0s, max_grad_data: 2.919734633986786, sgn switches: 0\n",
      "step 195 learning rate: 0.84981 loss: 0.24662, accuracy: 88.0%, max_grad: -0.00170, max_grad_neuron: l4n0s, max_grad_data: 2.9214302526622884, sgn switches: 0\n",
      "step 196 learning rate: 0.85576 loss: 0.24661, accuracy: 88.0%, max_grad: -0.00169, max_grad_neuron: l4n0s, max_grad_data: 2.923118989762511, sgn switches: 0\n",
      "step 197 learning rate: 0.86206 loss: 0.24661, accuracy: 88.0%, max_grad: -0.00168, max_grad_neuron: l4n0s, max_grad_data: 2.9248008963687155, sgn switches: 1\n",
      "step 198 learning rate: 0.86923 loss: 0.24660, accuracy: 88.0%, max_grad: -0.00168, max_grad_neuron: l4n0s, max_grad_data: 2.9264760100799148, sgn switches: 0\n",
      "step 199 learning rate: 0.87360 loss: 0.24660, accuracy: 88.0%, max_grad: -0.00167, max_grad_neuron: l4n0s, max_grad_data: 2.9281443937457143, sgn switches: 1\n",
      "step 200 learning rate: 0.87754 loss: 0.24659, accuracy: 88.0%, max_grad: -0.00166, max_grad_neuron: l4n0s, max_grad_data: 2.929806042899372, sgn switches: 2\n",
      "step 201 learning rate: 0.88178 loss: 0.24658, accuracy: 88.0%, max_grad: -0.00166, max_grad_neuron: l4n0s, max_grad_data: 2.9314611131128574, sgn switches: 2\n",
      "step 202 learning rate: 0.88079 loss: 0.24658, accuracy: 88.0%, max_grad: -0.00165, max_grad_neuron: l4n0s, max_grad_data: 2.933109364972553, sgn switches: 5\n",
      "step 203 learning rate: 0.86071 loss: 0.24657, accuracy: 88.0%, max_grad: -0.00164, max_grad_neuron: l4n0s, max_grad_data: 2.934751614456705, sgn switches: 8\n",
      "step 204 learning rate: 0.82576 loss: 0.24657, accuracy: 88.0%, max_grad: 0.00271, max_grad_neuron: l0n2w0, max_grad_data: -0.710781213452735, sgn switches: 13\n",
      "step 205 learning rate: 0.81431 loss: 0.24656, accuracy: 88.0%, max_grad: -0.00163, max_grad_neuron: l4n0s, max_grad_data: 2.9380148271688062, sgn switches: 7\n",
      "step 206 learning rate: 0.81671 loss: 0.24656, accuracy: 88.0%, max_grad: -0.00162, max_grad_neuron: l4n0s, max_grad_data: 2.939637110893079, sgn switches: 0\n",
      "step 207 learning rate: 0.81910 loss: 0.24655, accuracy: 88.0%, max_grad: -0.00162, max_grad_neuron: l4n0s, max_grad_data: 2.9412529891434502, sgn switches: 1\n",
      "step 208 learning rate: 0.82171 loss: 0.24655, accuracy: 88.0%, max_grad: -0.00161, max_grad_neuron: l4n0s, max_grad_data: 2.9428625048859285, sgn switches: 1\n",
      "step 209 learning rate: 0.82485 loss: 0.24654, accuracy: 88.0%, max_grad: -0.00160, max_grad_neuron: l4n0s, max_grad_data: 2.9444656999598484, sgn switches: 0\n",
      "step 210 learning rate: 0.82830 loss: 0.24654, accuracy: 88.0%, max_grad: -0.00160, max_grad_neuron: l4n0s, max_grad_data: 2.946062615952632, sgn switches: 0\n",
      "step 211 learning rate: 0.83210 loss: 0.24653, accuracy: 88.0%, max_grad: -0.00159, max_grad_neuron: l4n0s, max_grad_data: 2.947653294136714, sgn switches: 0\n",
      "step 212 learning rate: 0.83627 loss: 0.24653, accuracy: 88.0%, max_grad: -0.00158, max_grad_neuron: l4n0s, max_grad_data: 2.949237775527208, sgn switches: 0\n",
      "step 213 learning rate: 0.84087 loss: 0.24652, accuracy: 88.0%, max_grad: -0.00158, max_grad_neuron: l4n0s, max_grad_data: 2.9508161008568132, sgn switches: 0\n",
      "step 214 learning rate: 0.84592 loss: 0.24652, accuracy: 88.0%, max_grad: -0.00157, max_grad_neuron: l4n0s, max_grad_data: 2.9523883106049293, sgn switches: 0\n",
      "step 215 learning rate: 0.85148 loss: 0.24652, accuracy: 88.0%, max_grad: -0.00157, max_grad_neuron: l4n0s, max_grad_data: 2.9539544449823882, sgn switches: 0\n",
      "step 216 learning rate: 0.85760 loss: 0.24651, accuracy: 88.0%, max_grad: -0.00156, max_grad_neuron: l4n0s, max_grad_data: 2.9555145439681154, sgn switches: 0\n",
      "step 217 learning rate: 0.85626 loss: 0.24651, accuracy: 88.0%, max_grad: -0.00155, max_grad_neuron: l4n0s, max_grad_data: 2.957068647277212, sgn switches: 1\n",
      "step 218 learning rate: 0.86447 loss: 0.24650, accuracy: 88.0%, max_grad: -0.00155, max_grad_neuron: l4n0s, max_grad_data: 2.9586167944193047, sgn switches: 0\n",
      "step 219 learning rate: 0.87207 loss: 0.24650, accuracy: 88.0%, max_grad: -0.00154, max_grad_neuron: l4n0s, max_grad_data: 2.9601590245369462, sgn switches: 0\n",
      "step 220 learning rate: 0.87648 loss: 0.24649, accuracy: 88.0%, max_grad: -0.00154, max_grad_neuron: l4n0s, max_grad_data: 2.9616953657208134, sgn switches: 0\n",
      "step 221 learning rate: 0.87865 loss: 0.24649, accuracy: 88.0%, max_grad: -0.00153, max_grad_neuron: l4n0s, max_grad_data: 2.9632258889581484, sgn switches: 0\n",
      "step 222 learning rate: 0.88103 loss: 0.24648, accuracy: 88.0%, max_grad: -0.00152, max_grad_neuron: l4n0s, max_grad_data: 2.964750555996674, sgn switches: 0\n",
      "step 223 learning rate: 0.87886 loss: 0.24648, accuracy: 88.0%, max_grad: -0.00152, max_grad_neuron: l4n0s, max_grad_data: 2.9662696534348534, sgn switches: 2\n",
      "step 224 learning rate: 0.86053 loss: 0.24647, accuracy: 88.0%, max_grad: 0.00243, max_grad_neuron: l0n2w0, max_grad_data: -0.7132044652609812, sgn switches: 8\n",
      "step 225 learning rate: 0.83511 loss: 0.24647, accuracy: 88.0%, max_grad: -0.00151, max_grad_neuron: l4n0s, max_grad_data: 2.969290336359354, sgn switches: 10\n",
      "step 226 learning rate: 0.82588 loss: 0.24646, accuracy: 88.0%, max_grad: -0.00150, max_grad_neuron: l4n0s, max_grad_data: 2.9707918853806317, sgn switches: 10\n",
      "step 227 learning rate: 0.82708 loss: 0.24646, accuracy: 88.0%, max_grad: -0.00150, max_grad_neuron: l4n0s, max_grad_data: 2.9722878398178536, sgn switches: 2\n",
      "step 228 learning rate: 0.82914 loss: 0.24646, accuracy: 88.0%, max_grad: -0.00149, max_grad_neuron: l4n0s, max_grad_data: 2.9737781999182293, sgn switches: 0\n",
      "step 229 learning rate: 0.83141 loss: 0.24645, accuracy: 88.0%, max_grad: -0.00148, max_grad_neuron: l4n0s, max_grad_data: 2.97526299566906, sgn switches: 0\n",
      "step 230 learning rate: 0.83376 loss: 0.24645, accuracy: 88.0%, max_grad: -0.00148, max_grad_neuron: l4n0s, max_grad_data: 2.976742263748593, sgn switches: 2\n",
      "step 231 learning rate: 0.83649 loss: 0.24644, accuracy: 88.0%, max_grad: -0.00147, max_grad_neuron: l4n0s, max_grad_data: 2.978216040781907, sgn switches: 0\n",
      "step 232 learning rate: 0.83949 loss: 0.24644, accuracy: 88.0%, max_grad: -0.00147, max_grad_neuron: l4n0s, max_grad_data: 2.9796843624472884, sgn switches: 0\n",
      "step 233 learning rate: 0.84279 loss: 0.24644, accuracy: 88.0%, max_grad: -0.00146, max_grad_neuron: l4n0s, max_grad_data: 2.9811472638228653, sgn switches: 0\n",
      "step 234 learning rate: 0.84643 loss: 0.24643, accuracy: 88.0%, max_grad: -0.00146, max_grad_neuron: l4n0s, max_grad_data: 2.982604779658603, sgn switches: 0\n",
      "step 235 learning rate: 0.85043 loss: 0.24643, accuracy: 88.0%, max_grad: -0.00145, max_grad_neuron: l4n0s, max_grad_data: 2.9840569444761633, sgn switches: 0\n",
      "step 236 learning rate: 0.85482 loss: 0.24642, accuracy: 88.0%, max_grad: -0.00145, max_grad_neuron: l4n0s, max_grad_data: 2.985503792605555, sgn switches: 0\n",
      "step 237 learning rate: 0.85966 loss: 0.24642, accuracy: 88.0%, max_grad: -0.00144, max_grad_neuron: l4n0s, max_grad_data: 2.986945358197829, sgn switches: 0\n",
      "step 238 learning rate: 0.86498 loss: 0.24642, accuracy: 88.0%, max_grad: -0.00144, max_grad_neuron: l4n0s, max_grad_data: 2.9883816752356083, sgn switches: 0\n",
      "step 239 learning rate: 0.87083 loss: 0.24641, accuracy: 88.0%, max_grad: -0.00143, max_grad_neuron: l4n0s, max_grad_data: 2.989812777543646, sgn switches: 0\n",
      "step 240 learning rate: 0.87584 loss: 0.24641, accuracy: 88.0%, max_grad: -0.00143, max_grad_neuron: l4n0s, max_grad_data: 2.9912386988016406, sgn switches: 0\n",
      "step 241 learning rate: 0.87776 loss: 0.24640, accuracy: 88.0%, max_grad: -0.00142, max_grad_neuron: l4n0s, max_grad_data: 2.992659485334565, sgn switches: 1\n",
      "step 242 learning rate: 0.87826 loss: 0.24640, accuracy: 88.0%, max_grad: -0.00142, max_grad_neuron: l4n0s, max_grad_data: 2.994075155822531, sgn switches: 1\n",
      "step 243 learning rate: 0.87898 loss: 0.24639, accuracy: 88.0%, max_grad: -0.00141, max_grad_neuron: l4n0s, max_grad_data: 2.9954857597606077, sgn switches: 1\n",
      "step 244 learning rate: 0.87170 loss: 0.24639, accuracy: 88.0%, max_grad: -0.00141, max_grad_neuron: l4n0s, max_grad_data: 2.9968912946866406, sgn switches: 2\n",
      "step 245 learning rate: 0.87336 loss: 0.24639, accuracy: 88.0%, max_grad: -0.00140, max_grad_neuron: l4n0s, max_grad_data: 2.998291859678857, sgn switches: 1\n",
      "step 246 learning rate: 0.87520 loss: 0.24638, accuracy: 88.0%, max_grad: -0.00140, max_grad_neuron: l4n0s, max_grad_data: 2.9996873520451377, sgn switches: 1\n",
      "step 247 learning rate: 0.87657 loss: 0.24638, accuracy: 88.0%, max_grad: -0.00139, max_grad_neuron: l4n0s, max_grad_data: 3.0010780730045914, sgn switches: 2\n",
      "step 248 learning rate: 0.87742 loss: 0.24638, accuracy: 88.0%, max_grad: -0.00139, max_grad_neuron: l4n0s, max_grad_data: 3.0024634934384618, sgn switches: 4\n",
      "step 249 learning rate: 0.85190 loss: 0.24637, accuracy: 88.0%, max_grad: -0.00138, max_grad_neuron: l4n0s, max_grad_data: 3.0038448403413303, sgn switches: 9\n",
      "step 250 learning rate: 0.81305 loss: 0.24637, accuracy: 88.0%, max_grad: 0.00326, max_grad_neuron: l0n2w0, max_grad_data: -0.7154868629347368, sgn switches: 14\n",
      "step 251 learning rate: 0.80251 loss: 0.24636, accuracy: 88.0%, max_grad: -0.00137, max_grad_neuron: l4n0s, max_grad_data: 3.006590796564621, sgn switches: 5\n",
      "step 252 learning rate: 0.80577 loss: 0.24636, accuracy: 88.0%, max_grad: -0.00137, max_grad_neuron: l4n0s, max_grad_data: 3.007956910058492, sgn switches: 1\n",
      "step 253 learning rate: 0.80892 loss: 0.24636, accuracy: 88.0%, max_grad: -0.00136, max_grad_neuron: l4n0s, max_grad_data: 3.009318244529798, sgn switches: 0\n",
      "step 254 learning rate: 0.81232 loss: 0.24635, accuracy: 88.0%, max_grad: -0.00136, max_grad_neuron: l4n0s, max_grad_data: 3.0106748265538887, sgn switches: 1\n",
      "step 255 learning rate: 0.81604 loss: 0.24635, accuracy: 88.0%, max_grad: -0.00135, max_grad_neuron: l4n0s, max_grad_data: 3.0120266863325638, sgn switches: 1\n",
      "step 256 learning rate: 0.82022 loss: 0.24635, accuracy: 88.0%, max_grad: -0.00135, max_grad_neuron: l4n0s, max_grad_data: 3.0133738535802057, sgn switches: 0\n",
      "step 257 learning rate: 0.82482 loss: 0.24634, accuracy: 88.0%, max_grad: -0.00134, max_grad_neuron: l4n0s, max_grad_data: 3.014716357829209, sgn switches: 0\n",
      "step 258 learning rate: 0.82989 loss: 0.24634, accuracy: 88.0%, max_grad: -0.00134, max_grad_neuron: l4n0s, max_grad_data: 3.0160542285413263, sgn switches: 0\n",
      "step 259 learning rate: 0.83546 loss: 0.24634, accuracy: 88.0%, max_grad: -0.00133, max_grad_neuron: l4n0s, max_grad_data: 3.017387495122637, sgn switches: 0\n",
      "step 260 learning rate: 0.84158 loss: 0.24633, accuracy: 88.0%, max_grad: -0.00133, max_grad_neuron: l4n0s, max_grad_data: 3.0187161869296295, sgn switches: 0\n",
      "step 261 learning rate: 0.84832 loss: 0.24633, accuracy: 88.0%, max_grad: -0.00132, max_grad_neuron: l4n0s, max_grad_data: 3.0200403332786783, sgn switches: 0\n",
      "step 262 learning rate: 0.85573 loss: 0.24632, accuracy: 88.0%, max_grad: -0.00132, max_grad_neuron: l4n0s, max_grad_data: 3.021359963458209, sgn switches: 0\n",
      "step 263 learning rate: 0.86389 loss: 0.24632, accuracy: 88.0%, max_grad: -0.00132, max_grad_neuron: l4n0s, max_grad_data: 3.0226751067431272, sgn switches: 0\n",
      "step 264 learning rate: 0.87286 loss: 0.24632, accuracy: 88.0%, max_grad: -0.00131, max_grad_neuron: l4n0s, max_grad_data: 3.0239857924122684, sgn switches: 0\n",
      "step 265 learning rate: 0.88058 loss: 0.24631, accuracy: 88.0%, max_grad: -0.00131, max_grad_neuron: l4n0s, max_grad_data: 3.0252920497677334, sgn switches: 0\n",
      "step 266 learning rate: 0.88423 loss: 0.24631, accuracy: 88.0%, max_grad: -0.00130, max_grad_neuron: l4n0s, max_grad_data: 3.0265938960345955, sgn switches: 0\n",
      "step 267 learning rate: 0.88556 loss: 0.24631, accuracy: 88.0%, max_grad: -0.00130, max_grad_neuron: l4n0s, max_grad_data: 3.0278913857214578, sgn switches: 0\n",
      "step 268 learning rate: 0.88702 loss: 0.24630, accuracy: 88.0%, max_grad: -0.00129, max_grad_neuron: l4n0s, max_grad_data: 3.029184495603936, sgn switches: 0\n",
      "step 269 learning rate: 0.88753 loss: 0.24630, accuracy: 88.0%, max_grad: -0.00129, max_grad_neuron: l4n0s, max_grad_data: 3.030473402395688, sgn switches: 1\n",
      "step 270 learning rate: 0.88778 loss: 0.24630, accuracy: 88.0%, max_grad: 0.00185, max_grad_neuron: l0n2w0, max_grad_data: -0.7180017770280367, sgn switches: 3\n",
      "step 271 learning rate: 0.83610 loss: 0.24629, accuracy: 88.0%, max_grad: -0.00531, max_grad_neuron: l0n2w0, max_grad_data: -0.717003013398426, sgn switches: 11\n",
      "step 272 learning rate: 0.77307 loss: 0.24630, accuracy: 88.0%, max_grad: 0.01310, max_grad_neuron: l0n2w0, max_grad_data: -0.718234034685124, sgn switches: 18\n",
      "step 273 learning rate: 0.74662 loss: 0.24629, accuracy: 88.0%, max_grad: -0.00540, max_grad_neuron: l0n2w0, max_grad_data: -0.7179802900121102, sgn switches: 15\n",
      "step 274 learning rate: 0.74533 loss: 0.24628, accuracy: 88.0%, max_grad: -0.00127, max_grad_neuron: l4n0s, max_grad_data: 3.0368521871756715, sgn switches: 7\n",
      "step 275 learning rate: 0.74671 loss: 0.24628, accuracy: 88.0%, max_grad: -0.00126, max_grad_neuron: l4n0s, max_grad_data: 3.038115374076379, sgn switches: 4\n",
      "step 276 learning rate: 0.75000 loss: 0.24628, accuracy: 88.0%, max_grad: -0.00126, max_grad_neuron: l4n0s, max_grad_data: 3.0393744073272027, sgn switches: 2\n",
      "step 277 learning rate: 0.75393 loss: 0.24627, accuracy: 88.0%, max_grad: -0.00125, max_grad_neuron: l4n0s, max_grad_data: 3.040629306773136, sgn switches: 2\n",
      "step 278 learning rate: 0.75835 loss: 0.24627, accuracy: 88.0%, max_grad: -0.00125, max_grad_neuron: l4n0s, max_grad_data: 3.041880105568766, sgn switches: 0\n",
      "step 279 learning rate: 0.76322 loss: 0.24627, accuracy: 88.0%, max_grad: -0.00125, max_grad_neuron: l4n0s, max_grad_data: 3.043126833810045, sgn switches: 0\n",
      "step 280 learning rate: 0.76858 loss: 0.24626, accuracy: 88.0%, max_grad: -0.00124, max_grad_neuron: l4n0s, max_grad_data: 3.0443695187482573, sgn switches: 0\n",
      "step 281 learning rate: 0.77447 loss: 0.24626, accuracy: 88.0%, max_grad: -0.00124, max_grad_neuron: l4n0s, max_grad_data: 3.0456081864501607, sgn switches: 0\n",
      "step 282 learning rate: 0.78094 loss: 0.24626, accuracy: 88.0%, max_grad: -0.00123, max_grad_neuron: l4n0s, max_grad_data: 3.046842862581937, sgn switches: 0\n",
      "step 283 learning rate: 0.78807 loss: 0.24625, accuracy: 88.0%, max_grad: -0.00123, max_grad_neuron: l4n0s, max_grad_data: 3.0480735727254107, sgn switches: 0\n",
      "step 284 learning rate: 0.79591 loss: 0.24625, accuracy: 88.0%, max_grad: 0.00123, max_grad_neuron: l0n2w0, max_grad_data: -0.7184123177177234, sgn switches: 0\n",
      "step 285 learning rate: 0.80453 loss: 0.24625, accuracy: 88.0%, max_grad: 0.00123, max_grad_neuron: l0n2w0, max_grad_data: -0.7184948796105358, sgn switches: 0\n",
      "step 286 learning rate: 0.81402 loss: 0.24624, accuracy: 88.0%, max_grad: 0.00123, max_grad_neuron: l0n2w0, max_grad_data: -0.7185858929524201, sgn switches: 0\n",
      "step 287 learning rate: 0.82302 loss: 0.24624, accuracy: 88.0%, max_grad: 0.00124, max_grad_neuron: l0n2w0, max_grad_data: -0.7186862188610957, sgn switches: 0\n",
      "step 288 learning rate: 0.82827 loss: 0.24624, accuracy: 88.0%, max_grad: 0.00124, max_grad_neuron: l0n2w0, max_grad_data: -0.718796799041197, sgn switches: 0\n",
      "step 289 learning rate: 0.83046 loss: 0.24623, accuracy: 88.0%, max_grad: -0.00121, max_grad_neuron: l4n0s, max_grad_data: 3.055375968446586, sgn switches: 0\n",
      "step 290 learning rate: 0.83286 loss: 0.24623, accuracy: 88.0%, max_grad: -0.00120, max_grad_neuron: l4n0s, max_grad_data: 3.0565796162194907, sgn switches: 0\n",
      "step 291 learning rate: 0.83550 loss: 0.24623, accuracy: 88.0%, max_grad: -0.00120, max_grad_neuron: l4n0s, max_grad_data: 3.0577795324885066, sgn switches: 0\n",
      "step 292 learning rate: 0.83840 loss: 0.24622, accuracy: 88.0%, max_grad: -0.00120, max_grad_neuron: l4n0s, max_grad_data: 3.0589756489330893, sgn switches: 0\n",
      "step 293 learning rate: 0.84050 loss: 0.24622, accuracy: 88.0%, max_grad: -0.00119, max_grad_neuron: l4n0s, max_grad_data: 3.060168183151854, sgn switches: 1\n",
      "step 294 learning rate: 0.84247 loss: 0.24622, accuracy: 88.0%, max_grad: 0.00130, max_grad_neuron: l0n2w0, max_grad_data: -0.7196178892018261, sgn switches: 3\n",
      "step 295 learning rate: 0.82656 loss: 0.24621, accuracy: 88.0%, max_grad: -0.00119, max_grad_neuron: l4n0s, max_grad_data: 3.0625422710504027, sgn switches: 8\n",
      "step 296 learning rate: 0.79427 loss: 0.24621, accuracy: 88.0%, max_grad: 0.00334, max_grad_neuron: l0n2w0, max_grad_data: -0.7197345185039853, sgn switches: 13\n",
      "step 297 learning rate: 0.78553 loss: 0.24621, accuracy: 88.0%, max_grad: -0.00118, max_grad_neuron: l4n0s, max_grad_data: 3.0649006408018677, sgn switches: 5\n",
      "step 298 learning rate: 0.79139 loss: 0.24620, accuracy: 88.0%, max_grad: -0.00117, max_grad_neuron: l4n0s, max_grad_data: 3.0660746762406026, sgn switches: 1\n",
      "step 299 learning rate: 0.79795 loss: 0.24620, accuracy: 88.0%, max_grad: -0.00117, max_grad_neuron: l4n0s, max_grad_data: 3.06724512614801, sgn switches: 0\n",
      "step 300 learning rate: 0.80516 loss: 0.24620, accuracy: 88.0%, max_grad: -0.00117, max_grad_neuron: l4n0s, max_grad_data: 3.068412015436241, sgn switches: 0\n",
      "step 301 learning rate: 0.81300 loss: 0.24619, accuracy: 88.0%, max_grad: -0.00116, max_grad_neuron: l4n0s, max_grad_data: 3.069575367475806, sgn switches: 1\n",
      "step 302 learning rate: 0.82160 loss: 0.24619, accuracy: 88.0%, max_grad: -0.00116, max_grad_neuron: l4n0s, max_grad_data: 3.070735205298964, sgn switches: 1\n",
      "step 303 learning rate: 0.83117 loss: 0.24619, accuracy: 88.0%, max_grad: -0.00116, max_grad_neuron: l4n0s, max_grad_data: 3.0718915519905114, sgn switches: 0\n",
      "step 304 learning rate: 0.83587 loss: 0.24618, accuracy: 88.0%, max_grad: -0.00115, max_grad_neuron: l4n0s, max_grad_data: 3.0730444307229026, sgn switches: 0\n",
      "step 305 learning rate: 0.84042 loss: 0.24618, accuracy: 88.0%, max_grad: -0.00115, max_grad_neuron: l4n0s, max_grad_data: 3.0741938634176664, sgn switches: 0\n",
      "step 306 learning rate: 0.84525 loss: 0.24618, accuracy: 88.0%, max_grad: -0.00115, max_grad_neuron: l4n0s, max_grad_data: 3.075339874602048, sgn switches: 1\n",
      "step 307 learning rate: 0.85074 loss: 0.24617, accuracy: 88.0%, max_grad: -0.00114, max_grad_neuron: l4n0s, max_grad_data: 3.076482486095206, sgn switches: 0\n",
      "step 308 learning rate: 0.85678 loss: 0.24617, accuracy: 88.0%, max_grad: -0.00114, max_grad_neuron: l4n0s, max_grad_data: 3.0776217234086984, sgn switches: 0\n",
      "step 309 learning rate: 0.86343 loss: 0.24617, accuracy: 88.0%, max_grad: -0.00114, max_grad_neuron: l4n0s, max_grad_data: 3.078757606801634, sgn switches: 0\n",
      "step 310 learning rate: 0.87074 loss: 0.24616, accuracy: 88.0%, max_grad: -0.00113, max_grad_neuron: l4n0s, max_grad_data: 3.0798901662986813, sgn switches: 0\n",
      "step 311 learning rate: 0.87735 loss: 0.24616, accuracy: 88.0%, max_grad: -0.00113, max_grad_neuron: l4n0s, max_grad_data: 3.0810194119204097, sgn switches: 0\n",
      "step 312 learning rate: 0.88056 loss: 0.24616, accuracy: 88.0%, max_grad: -0.00113, max_grad_neuron: l4n0s, max_grad_data: 3.0821453890267887, sgn switches: 1\n",
      "step 313 learning rate: 0.88150 loss: 0.24615, accuracy: 88.0%, max_grad: -0.00112, max_grad_neuron: l4n0s, max_grad_data: 3.083268056430102, sgn switches: 1\n",
      "step 314 learning rate: 0.88130 loss: 0.24615, accuracy: 88.0%, max_grad: -0.00112, max_grad_neuron: l4n0s, max_grad_data: 3.0843876463456095, sgn switches: 3\n",
      "step 315 learning rate: 0.86357 loss: 0.24615, accuracy: 88.0%, max_grad: 0.00241, max_grad_neuron: l0n2w0, max_grad_data: -0.721824424487907, sgn switches: 8\n",
      "step 316 learning rate: 0.80445 loss: 0.24615, accuracy: 88.0%, max_grad: -0.00590, max_grad_neuron: l0n2w0, max_grad_data: -0.7211113546535792, sgn switches: 15\n",
      "step 317 learning rate: 0.74940 loss: 0.24614, accuracy: 88.0%, max_grad: 0.00714, max_grad_neuron: l0n2w0, max_grad_data: -0.7215428609549693, sgn switches: 19\n",
      "step 318 learning rate: 0.73802 loss: 0.24614, accuracy: 88.0%, max_grad: -0.00111, max_grad_neuron: l4n0s, max_grad_data: 3.0888327087141683, sgn switches: 7\n",
      "step 319 learning rate: 0.74138 loss: 0.24613, accuracy: 88.0%, max_grad: -0.00110, max_grad_neuron: l4n0s, max_grad_data: 3.089936137693651, sgn switches: 2\n",
      "step 320 learning rate: 0.74616 loss: 0.24613, accuracy: 88.0%, max_grad: -0.00110, max_grad_neuron: l4n0s, max_grad_data: 3.0910364456717736, sgn switches: 0\n",
      "step 321 learning rate: 0.75128 loss: 0.24613, accuracy: 88.0%, max_grad: -0.00110, max_grad_neuron: l4n0s, max_grad_data: 3.092133647660266, sgn switches: 2\n",
      "step 322 learning rate: 0.75705 loss: 0.24612, accuracy: 88.0%, max_grad: -0.00109, max_grad_neuron: l4n0s, max_grad_data: 3.0932277633755536, sgn switches: 0\n",
      "step 323 learning rate: 0.76340 loss: 0.24612, accuracy: 88.0%, max_grad: -0.00109, max_grad_neuron: l4n0s, max_grad_data: 3.09431881301833, sgn switches: 0\n",
      "step 324 learning rate: 0.77039 loss: 0.24612, accuracy: 88.0%, max_grad: -0.00109, max_grad_neuron: l4n0s, max_grad_data: 3.0954068167187483, sgn switches: 0\n",
      "step 325 learning rate: 0.77807 loss: 0.24612, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.0964917947099155, sgn switches: 0\n",
      "step 326 learning rate: 0.78652 loss: 0.24611, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.0975737672206307, sgn switches: 0\n",
      "step 327 learning rate: 0.79582 loss: 0.24611, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.0986527545550526, sgn switches: 0\n",
      "step 328 learning rate: 0.80604 loss: 0.24611, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.0997287770071287, sgn switches: 0\n",
      "step 329 learning rate: 0.80321 loss: 0.24610, accuracy: 88.0%, max_grad: -0.00225, max_grad_neuron: l0n2b, max_grad_data: -0.34161035452739563, sgn switches: 3\n",
      "step 330 learning rate: 0.77397 loss: 0.24610, accuracy: 88.0%, max_grad: 0.00330, max_grad_neuron: l0n2b, max_grad_data: -0.3421980394345689, sgn switches: 12\n",
      "step 331 learning rate: 0.77507 loss: 0.24610, accuracy: 88.0%, max_grad: 0.00180, max_grad_neuron: l0n2b, max_grad_data: -0.342550787486016, sgn switches: 4\n",
      "step 332 learning rate: 0.77006 loss: 0.24609, accuracy: 88.0%, max_grad: -0.00136, max_grad_neuron: l0n2b, max_grad_data: -0.3424171487242561, sgn switches: 12\n",
      "step 333 learning rate: 0.77466 loss: 0.24609, accuracy: 88.0%, max_grad: -0.00114, max_grad_neuron: l4n0s, max_grad_data: 3.1053107101846167, sgn switches: 0\n",
      "step 334 learning rate: 0.77017 loss: 0.24609, accuracy: 88.0%, max_grad: 0.00256, max_grad_neuron: l0n2b, max_grad_data: -0.34250614619317094, sgn switches: 10\n",
      "step 335 learning rate: 0.77025 loss: 0.24608, accuracy: 88.0%, max_grad: -0.00114, max_grad_neuron: l4n0s, max_grad_data: 3.107503022728039, sgn switches: 7\n",
      "step 336 learning rate: 0.77300 loss: 0.24608, accuracy: 88.0%, max_grad: -0.00113, max_grad_neuron: l4n0s, max_grad_data: 3.1086357177613824, sgn switches: 4\n",
      "step 337 learning rate: 0.77603 loss: 0.24608, accuracy: 88.0%, max_grad: -0.00113, max_grad_neuron: l4n0s, max_grad_data: 3.109764836789003, sgn switches: 3\n",
      "step 338 learning rate: 0.77944 loss: 0.24608, accuracy: 88.0%, max_grad: -0.00113, max_grad_neuron: l4n0s, max_grad_data: 3.11089038034877, sgn switches: 0\n",
      "step 339 learning rate: 0.78319 loss: 0.24607, accuracy: 88.0%, max_grad: 0.00113, max_grad_neuron: l0n2b, max_grad_data: -0.3427668725817194, sgn switches: 0\n",
      "step 340 learning rate: 0.78731 loss: 0.24607, accuracy: 88.0%, max_grad: 0.00123, max_grad_neuron: l0n2b, max_grad_data: -0.3428848786332988, sgn switches: 0\n",
      "step 341 learning rate: 0.79185 loss: 0.24607, accuracy: 88.0%, max_grad: 0.00126, max_grad_neuron: l0n2b, max_grad_data: -0.34301774235869836, sgn switches: 0\n",
      "step 342 learning rate: 0.79684 loss: 0.24606, accuracy: 88.0%, max_grad: 0.00130, max_grad_neuron: l0n2b, max_grad_data: -0.3431679586449706, sgn switches: 0\n",
      "step 343 learning rate: 0.80077 loss: 0.24606, accuracy: 88.0%, max_grad: 0.00123, max_grad_neuron: l0n2b, max_grad_data: -0.3433238896092992, sgn switches: 2\n",
      "step 344 learning rate: 0.79267 loss: 0.24606, accuracy: 88.0%, max_grad: 0.00166, max_grad_neuron: l0n2w0, max_grad_data: -0.7225517597011873, sgn switches: 5\n",
      "step 345 learning rate: 0.79118 loss: 0.24606, accuracy: 88.0%, max_grad: -0.00110, max_grad_neuron: l4n0s, max_grad_data: 3.1186755405729643, sgn switches: 3\n",
      "step 346 learning rate: 0.79467 loss: 0.24605, accuracy: 88.0%, max_grad: -0.00110, max_grad_neuron: l4n0s, max_grad_data: 3.1197750508781237, sgn switches: 0\n",
      "step 347 learning rate: 0.79672 loss: 0.24605, accuracy: 88.0%, max_grad: -0.00110, max_grad_neuron: l4n0s, max_grad_data: 3.120871481373623, sgn switches: 0\n",
      "step 348 learning rate: 0.79897 loss: 0.24605, accuracy: 88.0%, max_grad: -0.00109, max_grad_neuron: l4n0s, max_grad_data: 3.1219648435138208, sgn switches: 0\n",
      "step 349 learning rate: 0.80117 loss: 0.24604, accuracy: 88.0%, max_grad: -0.00109, max_grad_neuron: l4n0s, max_grad_data: 3.1230551539924676, sgn switches: 1\n",
      "step 350 learning rate: 0.80387 loss: 0.24604, accuracy: 88.0%, max_grad: -0.00109, max_grad_neuron: l4n0s, max_grad_data: 3.1241424319866766, sgn switches: 0\n",
      "step 351 learning rate: 0.80684 loss: 0.24604, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.1252266984147523, sgn switches: 0\n",
      "step 352 learning rate: 0.81011 loss: 0.24604, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.1263079752208505, sgn switches: 0\n",
      "step 353 learning rate: 0.81329 loss: 0.24603, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.127386285017716, sgn switches: 1\n",
      "step 354 learning rate: 0.81720 loss: 0.24603, accuracy: 88.0%, max_grad: -0.00108, max_grad_neuron: l4n0s, max_grad_data: 3.1284616509210017, sgn switches: 0\n",
      "step 355 learning rate: 0.82150 loss: 0.24603, accuracy: 88.0%, max_grad: -0.00107, max_grad_neuron: l4n0s, max_grad_data: 3.129534096410321, sgn switches: 0\n",
      "step 356 learning rate: 0.82564 loss: 0.24602, accuracy: 88.0%, max_grad: -0.00107, max_grad_neuron: l4n0s, max_grad_data: 3.1306036453452104, sgn switches: 1\n",
      "step 357 learning rate: 0.83014 loss: 0.24602, accuracy: 88.0%, max_grad: -0.00107, max_grad_neuron: l4n0s, max_grad_data: 3.1316703220048914, sgn switches: 1\n",
      "step 358 learning rate: 0.83540 loss: 0.24602, accuracy: 88.0%, max_grad: -0.00106, max_grad_neuron: l4n0s, max_grad_data: 3.132734151004748, sgn switches: 1\n",
      "step 359 learning rate: 0.84152 loss: 0.24601, accuracy: 88.0%, max_grad: -0.00106, max_grad_neuron: l4n0s, max_grad_data: 3.1337951574262113, sgn switches: 0\n",
      "step 360 learning rate: 0.84825 loss: 0.24601, accuracy: 88.0%, max_grad: -0.00106, max_grad_neuron: l4n0s, max_grad_data: 3.134853366479338, sgn switches: 0\n",
      "step 361 learning rate: 0.85565 loss: 0.24601, accuracy: 88.0%, max_grad: -0.00106, max_grad_neuron: l4n0s, max_grad_data: 3.1359088042830643, sgn switches: 0\n",
      "step 362 learning rate: 0.86380 loss: 0.24600, accuracy: 88.0%, max_grad: -0.00105, max_grad_neuron: l4n0s, max_grad_data: 3.136961496405792, sgn switches: 0\n",
      "step 363 learning rate: 0.87130 loss: 0.24600, accuracy: 88.0%, max_grad: -0.00105, max_grad_neuron: l4n0s, max_grad_data: 3.138011471976828, sgn switches: 0\n",
      "step 364 learning rate: 0.87826 loss: 0.24600, accuracy: 88.0%, max_grad: -0.00105, max_grad_neuron: l4n0s, max_grad_data: 3.1390587503152214, sgn switches: 0\n",
      "step 365 learning rate: 0.88268 loss: 0.24599, accuracy: 88.0%, max_grad: -0.00104, max_grad_neuron: l4n0s, max_grad_data: 3.1401034136331636, sgn switches: 0\n",
      "step 366 learning rate: 0.88252 loss: 0.24599, accuracy: 88.0%, max_grad: 0.00162, max_grad_neuron: l0n2w0, max_grad_data: -0.7246796887062574, sgn switches: 4\n",
      "step 367 learning rate: 0.82978 loss: 0.24598, accuracy: 88.0%, max_grad: -0.00481, max_grad_neuron: l0n2w0, max_grad_data: -0.7240173451267101, sgn switches: 12\n",
      "step 368 learning rate: 0.75374 loss: 0.24599, accuracy: 88.0%, max_grad: 0.01986, max_grad_neuron: l0n2w0, max_grad_data: -0.7253834632733352, sgn switches: 20\n",
      "step 369 learning rate: 0.70784 loss: 0.24599, accuracy: 88.0%, max_grad: -0.02008, max_grad_neuron: l0n2w0, max_grad_data: -0.7246925141421735, sgn switches: 21\n",
      "step 370 learning rate: 0.68731 loss: 0.24597, accuracy: 88.0%, max_grad: 0.00367, max_grad_neuron: l0n2w0, max_grad_data: -0.7247555695126142, sgn switches: 20\n",
      "step 371 learning rate: 0.68991 loss: 0.24597, accuracy: 88.0%, max_grad: 0.00219, max_grad_neuron: l0n2b, max_grad_data: -0.34794154666627697, sgn switches: 0\n",
      "step 372 learning rate: 0.68745 loss: 0.24597, accuracy: 88.0%, max_grad: 0.00195, max_grad_neuron: l0n2b, max_grad_data: -0.3480890111036278, sgn switches: 4\n",
      "step 373 learning rate: 0.68860 loss: 0.24596, accuracy: 88.0%, max_grad: 0.00176, max_grad_neuron: l0n2b, max_grad_data: -0.34823547526155546, sgn switches: 1\n",
      "step 374 learning rate: 0.69118 loss: 0.24596, accuracy: 88.0%, max_grad: 0.00159, max_grad_neuron: l0n2b, max_grad_data: -0.34838112152771056, sgn switches: 2\n",
      "step 375 learning rate: 0.69417 loss: 0.24596, accuracy: 88.0%, max_grad: 0.00144, max_grad_neuron: l0n2b, max_grad_data: -0.3485260668205372, sgn switches: 0\n",
      "step 376 learning rate: 0.69746 loss: 0.24595, accuracy: 88.0%, max_grad: 0.00130, max_grad_neuron: l0n2b, max_grad_data: -0.34867040794773696, sgn switches: 0\n",
      "step 377 learning rate: 0.70108 loss: 0.24595, accuracy: 88.0%, max_grad: 0.00118, max_grad_neuron: l0n2b, max_grad_data: -0.34881428787046326, sgn switches: 0\n",
      "step 378 learning rate: 0.70506 loss: 0.24595, accuracy: 88.0%, max_grad: 0.00107, max_grad_neuron: l0n2b, max_grad_data: -0.34895796627737397, sgn switches: 0\n",
      "step 379 learning rate: 0.70943 loss: 0.24594, accuracy: 88.0%, max_grad: -0.00101, max_grad_neuron: l4n0s, max_grad_data: 3.1544445554917737, sgn switches: 0\n",
      "step 380 learning rate: 0.71425 loss: 0.24594, accuracy: 88.0%, max_grad: -0.00101, max_grad_neuron: l4n0s, max_grad_data: 3.155450067080942, sgn switches: 0\n",
      "step 381 learning rate: 0.71954 loss: 0.24593, accuracy: 88.0%, max_grad: -0.00100, max_grad_neuron: l4n0s, max_grad_data: 3.156453190919595, sgn switches: 0\n",
      "step 382 learning rate: 0.72537 loss: 0.24593, accuracy: 88.0%, max_grad: -0.00100, max_grad_neuron: l4n0s, max_grad_data: 3.1574539450999857, sgn switches: 0\n",
      "step 383 learning rate: 0.73147 loss: 0.24593, accuracy: 88.0%, max_grad: -0.00100, max_grad_neuron: l4n0s, max_grad_data: 3.1584523482688573, sgn switches: 1\n",
      "step 384 learning rate: 0.73778 loss: 0.24592, accuracy: 88.0%, max_grad: -0.00100, max_grad_neuron: l4n0s, max_grad_data: 3.1594484195917736, sgn switches: 0\n",
      "step 385 learning rate: 0.74310 loss: 0.24592, accuracy: 88.0%, max_grad: -0.00099, max_grad_neuron: l4n0s, max_grad_data: 3.1604421786198054, sgn switches: 0\n",
      "step 386 learning rate: 0.74765 loss: 0.24592, accuracy: 88.0%, max_grad: -0.00099, max_grad_neuron: l4n0s, max_grad_data: 3.161433645123158, sgn switches: 1\n",
      "step 387 learning rate: 0.75306 loss: 0.24591, accuracy: 88.0%, max_grad: -0.00099, max_grad_neuron: l4n0s, max_grad_data: 3.1624228391269122, sgn switches: 0\n",
      "step 388 learning rate: 0.75901 loss: 0.24591, accuracy: 88.0%, max_grad: -0.00099, max_grad_neuron: l4n0s, max_grad_data: 3.1634097809931228, sgn switches: 0\n",
      "step 389 learning rate: 0.76502 loss: 0.24590, accuracy: 88.0%, max_grad: -0.00098, max_grad_neuron: l4n0s, max_grad_data: 3.164394491217345, sgn switches: 1\n",
      "step 390 learning rate: 0.77216 loss: 0.24590, accuracy: 88.0%, max_grad: -0.00098, max_grad_neuron: l4n0s, max_grad_data: 3.1653769909762333, sgn switches: 0\n",
      "step 391 learning rate: 0.77937 loss: 0.24589, accuracy: 88.0%, max_grad: -0.00098, max_grad_neuron: l4n0s, max_grad_data: 3.166357301106608, sgn switches: 1\n",
      "step 392 learning rate: 0.78795 loss: 0.24589, accuracy: 88.0%, max_grad: -0.00098, max_grad_neuron: l4n0s, max_grad_data: 3.1673354445634665, sgn switches: 0\n",
      "step 393 learning rate: 0.79740 loss: 0.24589, accuracy: 88.0%, max_grad: -0.00098, max_grad_neuron: l4n0s, max_grad_data: 3.168311439345591, sgn switches: 0\n",
      "step 394 learning rate: 0.80778 loss: 0.24588, accuracy: 88.0%, max_grad: -0.00097, max_grad_neuron: l4n0s, max_grad_data: 3.1692853217795967, sgn switches: 0\n",
      "step 395 learning rate: 0.81920 loss: 0.24588, accuracy: 88.0%, max_grad: 0.00099, max_grad_neuron: l0n2w0, max_grad_data: -0.7262233528725327, sgn switches: 0\n",
      "step 396 learning rate: 0.82227 loss: 0.24587, accuracy: 88.0%, max_grad: -0.00111, max_grad_neuron: l0n2w1, max_grad_data: 2.37550327067138, sgn switches: 3\n",
      "step 397 learning rate: 0.80050 loss: 0.24587, accuracy: 88.0%, max_grad: 0.00517, max_grad_neuron: l0n2w0, max_grad_data: -0.7264581835095261, sgn switches: 13\n",
      "step 398 learning rate: 0.78595 loss: 0.24586, accuracy: 88.0%, max_grad: -0.00255, max_grad_neuron: l0n2w0, max_grad_data: -0.7263987155934203, sgn switches: 14\n",
      "step 399 learning rate: 0.78957 loss: 0.24586, accuracy: 88.0%, max_grad: 0.00135, max_grad_neuron: l0n2b, max_grad_data: -0.3522709273702545, sgn switches: 9\n",
      "step 400 learning rate: 0.79333 loss: 0.24585, accuracy: 88.0%, max_grad: 0.00170, max_grad_neuron: l0n2b, max_grad_data: -0.35235005169362266, sgn switches: 0\n",
      "step 401 learning rate: 0.79539 loss: 0.24585, accuracy: 88.0%, max_grad: 0.00181, max_grad_neuron: l0n2b, max_grad_data: -0.3524427009040953, sgn switches: 0\n",
      "step 402 learning rate: 0.79751 loss: 0.24584, accuracy: 88.0%, max_grad: 0.00181, max_grad_neuron: l0n2b, max_grad_data: -0.35254481241431246, sgn switches: 0\n",
      "step 403 learning rate: 0.79985 loss: 0.24584, accuracy: 88.0%, max_grad: 0.00177, max_grad_neuron: l0n2b, max_grad_data: -0.352654221032986, sgn switches: 0\n",
      "step 404 learning rate: 0.80241 loss: 0.24584, accuracy: 88.0%, max_grad: 0.00169, max_grad_neuron: l0n2b, max_grad_data: -0.35276963740712364, sgn switches: 0\n",
      "step 405 learning rate: 0.80523 loss: 0.24583, accuracy: 88.0%, max_grad: 0.00161, max_grad_neuron: l0n2b, max_grad_data: -0.3528903165603401, sgn switches: 0\n",
      "step 406 learning rate: 0.80834 loss: 0.24583, accuracy: 88.0%, max_grad: 0.00165, max_grad_neuron: l0n2w0, max_grad_data: -0.7266053528060046, sgn switches: 0\n",
      "step 407 learning rate: 0.81175 loss: 0.24582, accuracy: 88.0%, max_grad: 0.00170, max_grad_neuron: l0n2w0, max_grad_data: -0.7266477231973316, sgn switches: 0\n",
      "step 408 learning rate: 0.81551 loss: 0.24582, accuracy: 88.0%, max_grad: 0.00174, max_grad_neuron: l0n2w0, max_grad_data: -0.7266956266621873, sgn switches: 0\n",
      "step 409 learning rate: 0.81964 loss: 0.24581, accuracy: 88.0%, max_grad: 0.00179, max_grad_neuron: l0n2w0, max_grad_data: -0.726749679748547, sgn switches: 0\n",
      "step 410 learning rate: 0.82418 loss: 0.24581, accuracy: 88.0%, max_grad: 0.00183, max_grad_neuron: l0n2w0, max_grad_data: -0.7268105565441545, sgn switches: 0\n",
      "step 411 learning rate: 0.82918 loss: 0.24580, accuracy: 88.0%, max_grad: 0.00187, max_grad_neuron: l0n2w0, max_grad_data: -0.7268790027538601, sgn switches: 0\n",
      "step 412 learning rate: 0.83468 loss: 0.24580, accuracy: 88.0%, max_grad: 0.00191, max_grad_neuron: l0n2w0, max_grad_data: -0.7269558457415679, sgn switches: 0\n",
      "step 413 learning rate: 0.84073 loss: 0.24579, accuracy: 88.0%, max_grad: 0.00195, max_grad_neuron: l0n2w0, max_grad_data: -0.7270420041408128, sgn switches: 0\n",
      "step 414 learning rate: 0.84738 loss: 0.24578, accuracy: 88.0%, max_grad: 0.00198, max_grad_neuron: l0n2w0, max_grad_data: -0.7271384975034573, sgn switches: 0\n",
      "step 415 learning rate: 0.85470 loss: 0.24578, accuracy: 88.0%, max_grad: 0.00202, max_grad_neuron: l0n2w0, max_grad_data: -0.7272464586210997, sgn switches: 0\n",
      "step 416 learning rate: 0.86218 loss: 0.24577, accuracy: 88.0%, max_grad: 0.00205, max_grad_neuron: l0n2w0, max_grad_data: -0.7273671433161204, sgn switches: 0\n",
      "step 417 learning rate: 0.86708 loss: 0.24577, accuracy: 88.0%, max_grad: 0.00209, max_grad_neuron: l0n2w0, max_grad_data: -0.7275027847593142, sgn switches: 0\n",
      "step 418 learning rate: 0.86777 loss: 0.24576, accuracy: 88.0%, max_grad: 0.00200, max_grad_neuron: l0n2w0, max_grad_data: -0.7276450857928243, sgn switches: 1\n",
      "step 419 learning rate: 0.85612 loss: 0.24575, accuracy: 88.0%, max_grad: 0.00178, max_grad_neuron: l0n2w0, max_grad_data: -0.727784702503296, sgn switches: 6\n",
      "step 420 learning rate: 0.79239 loss: 0.24575, accuracy: 88.0%, max_grad: 0.00557, max_grad_neuron: l0n2w0, max_grad_data: -0.7282651736082649, sgn switches: 15\n",
      "step 421 learning rate: 0.71090 loss: 0.24575, accuracy: 88.0%, max_grad: -0.01336, max_grad_neuron: l0n2w0, max_grad_data: -0.7276894389147494, sgn switches: 23\n",
      "step 422 learning rate: 0.66230 loss: 0.24574, accuracy: 88.0%, max_grad: 0.01314, max_grad_neuron: l0n2w0, max_grad_data: -0.72797270610836, sgn switches: 24\n",
      "step 423 learning rate: 0.65636 loss: 0.24573, accuracy: 88.0%, max_grad: 0.00257, max_grad_neuron: l0n2b, max_grad_data: -0.35530568328154943, sgn switches: 6\n",
      "step 424 learning rate: 0.66030 loss: 0.24573, accuracy: 88.0%, max_grad: 0.00307, max_grad_neuron: l0n2b, max_grad_data: -0.3553657086438636, sgn switches: 2\n",
      "step 425 learning rate: 0.66504 loss: 0.24573, accuracy: 88.0%, max_grad: 0.00345, max_grad_neuron: l0n2b, max_grad_data: -0.35544000260983005, sgn switches: 0\n",
      "step 426 learning rate: 0.67026 loss: 0.24572, accuracy: 88.0%, max_grad: 0.00370, max_grad_neuron: l0n2b, max_grad_data: -0.3555275367348582, sgn switches: 0\n",
      "step 427 learning rate: 0.67599 loss: 0.24572, accuracy: 88.0%, max_grad: 0.00381, max_grad_neuron: l0n2b, max_grad_data: -0.355626768884692, sgn switches: 0\n",
      "step 428 learning rate: 0.68230 loss: 0.24571, accuracy: 88.0%, max_grad: 0.00381, max_grad_neuron: l0n2b, max_grad_data: -0.3557358889558496, sgn switches: 0\n",
      "step 429 learning rate: 0.68924 loss: 0.24571, accuracy: 88.0%, max_grad: 0.00371, max_grad_neuron: l0n2b, max_grad_data: -0.3558529830025596, sgn switches: 0\n",
      "step 430 learning rate: 0.69687 loss: 0.24570, accuracy: 88.0%, max_grad: 0.00355, max_grad_neuron: l0n2b, max_grad_data: -0.35597619301415223, sgn switches: 0\n",
      "step 431 learning rate: 0.70527 loss: 0.24570, accuracy: 88.0%, max_grad: 0.00335, max_grad_neuron: l0n2b, max_grad_data: -0.356103889649877, sgn switches: 0\n",
      "step 432 learning rate: 0.71451 loss: 0.24569, accuracy: 88.0%, max_grad: 0.00312, max_grad_neuron: l0n2b, max_grad_data: -0.3562348298359351, sgn switches: 0\n",
      "step 433 learning rate: 0.72467 loss: 0.24568, accuracy: 88.0%, max_grad: 0.00289, max_grad_neuron: l0n2b, max_grad_data: -0.3563682589917252, sgn switches: 0\n",
      "step 434 learning rate: 0.73584 loss: 0.24568, accuracy: 88.0%, max_grad: 0.00267, max_grad_neuron: l0n2b, max_grad_data: -0.3565039287741474, sgn switches: 0\n",
      "step 435 learning rate: 0.74434 loss: 0.24567, accuracy: 88.0%, max_grad: 0.00247, max_grad_neuron: l0n2b, max_grad_data: -0.35664202668423267, sgn switches: 1\n",
      "step 436 learning rate: 0.75749 loss: 0.24567, accuracy: 88.0%, max_grad: 0.00229, max_grad_neuron: l0n2b, max_grad_data: -0.3567830193688583, sgn switches: 0\n",
      "step 437 learning rate: 0.76306 loss: 0.24566, accuracy: 88.0%, max_grad: 0.00214, max_grad_neuron: l0n2b, max_grad_data: -0.3569275503816624, sgn switches: 1\n",
      "step 438 learning rate: 0.76769 loss: 0.24566, accuracy: 88.0%, max_grad: 0.00200, max_grad_neuron: l0n2b, max_grad_data: -0.3570762392141366, sgn switches: 0\n",
      "step 439 learning rate: 0.76381 loss: 0.24565, accuracy: 88.0%, max_grad: 0.00187, max_grad_neuron: l0n2b, max_grad_data: -0.35722938596079634, sgn switches: 1\n",
      "step 440 learning rate: 0.76922 loss: 0.24564, accuracy: 88.0%, max_grad: 0.00176, max_grad_neuron: l0n2b, max_grad_data: -0.357387988529915, sgn switches: 0\n",
      "step 441 learning rate: 0.77518 loss: 0.24564, accuracy: 88.0%, max_grad: 0.00166, max_grad_neuron: l0n2b, max_grad_data: -0.35755174133240547, sgn switches: 0\n",
      "step 442 learning rate: 0.78173 loss: 0.24563, accuracy: 88.0%, max_grad: 0.00160, max_grad_neuron: l0n2b, max_grad_data: -0.35772573850667966, sgn switches: 0\n",
      "step 443 learning rate: 0.78753 loss: 0.24562, accuracy: 88.0%, max_grad: 0.00138, max_grad_neuron: l0n2b, max_grad_data: -0.3578907517577845, sgn switches: 1\n",
      "step 444 learning rate: 0.78118 loss: 0.24562, accuracy: 88.0%, max_grad: 0.00488, max_grad_neuron: l0n2w0, max_grad_data: -0.7289913956485653, sgn switches: 6\n",
      "step 445 learning rate: 0.75500 loss: 0.24561, accuracy: 88.0%, max_grad: -0.00219, max_grad_neuron: l0n2w1, max_grad_data: 2.3840268293233984, sgn switches: 15\n",
      "step 446 learning rate: 0.74280 loss: 0.24560, accuracy: 88.0%, max_grad: 0.00241, max_grad_neuron: l0n2b, max_grad_data: -0.3581840938280723, sgn switches: 12\n",
      "step 447 learning rate: 0.74277 loss: 0.24560, accuracy: 88.0%, max_grad: 0.00289, max_grad_neuron: l0n2b, max_grad_data: -0.3582887055533119, sgn switches: 1\n",
      "step 448 learning rate: 0.74769 loss: 0.24559, accuracy: 88.0%, max_grad: 0.00295, max_grad_neuron: l0n2b, max_grad_data: -0.3584063915203088, sgn switches: 0\n",
      "step 449 learning rate: 0.75310 loss: 0.24558, accuracy: 88.0%, max_grad: 0.00285, max_grad_neuron: l0n2b, max_grad_data: -0.3585313159793147, sgn switches: 0\n",
      "step 450 learning rate: 0.75578 loss: 0.24558, accuracy: 88.0%, max_grad: 0.00268, max_grad_neuron: l0n2b, max_grad_data: -0.3586606029461297, sgn switches: 1\n",
      "step 451 learning rate: 0.76201 loss: 0.24557, accuracy: 88.0%, max_grad: 0.00250, max_grad_neuron: l0n2b, max_grad_data: -0.3587928952287169, sgn switches: 0\n",
      "step 452 learning rate: 0.76885 loss: 0.24556, accuracy: 88.0%, max_grad: 0.00231, max_grad_neuron: l0n2b, max_grad_data: -0.35892776241662755, sgn switches: 0\n",
      "step 453 learning rate: 0.76910 loss: 0.24556, accuracy: 88.0%, max_grad: 0.00214, max_grad_neuron: l0n2b, max_grad_data: -0.3590653540567062, sgn switches: 1\n",
      "step 454 learning rate: 0.77343 loss: 0.24555, accuracy: 88.0%, max_grad: 0.00199, max_grad_neuron: l0n2b, max_grad_data: -0.35920579080496107, sgn switches: 0\n",
      "step 455 learning rate: 0.77819 loss: 0.24554, accuracy: 88.0%, max_grad: 0.00193, max_grad_neuron: l0n2w0, max_grad_data: -0.7292315809417713, sgn switches: 0\n",
      "step 456 learning rate: 0.78343 loss: 0.24553, accuracy: 88.0%, max_grad: 0.00199, max_grad_neuron: l0n2w0, max_grad_data: -0.7292830796145549, sgn switches: 0\n",
      "step 457 learning rate: 0.78919 loss: 0.24553, accuracy: 88.0%, max_grad: 0.00204, max_grad_neuron: l0n2w0, max_grad_data: -0.7293412583547115, sgn switches: 0\n",
      "step 458 learning rate: 0.79553 loss: 0.24552, accuracy: 88.0%, max_grad: 0.00209, max_grad_neuron: l0n2w0, max_grad_data: -0.72940680729216, sgn switches: 0\n",
      "step 459 learning rate: 0.80250 loss: 0.24551, accuracy: 88.0%, max_grad: 0.00214, max_grad_neuron: l0n2w0, max_grad_data: -0.7294805210295853, sgn switches: 0\n",
      "step 460 learning rate: 0.81017 loss: 0.24550, accuracy: 88.0%, max_grad: 0.00218, max_grad_neuron: l0n2w0, max_grad_data: -0.729563238933545, sgn switches: 0\n",
      "step 461 learning rate: 0.81718 loss: 0.24549, accuracy: 88.0%, max_grad: 0.00222, max_grad_neuron: l0n2w0, max_grad_data: -0.7296559999436375, sgn switches: 0\n",
      "step 462 learning rate: 0.82309 loss: 0.24549, accuracy: 88.0%, max_grad: 0.00228, max_grad_neuron: l0n2w0, max_grad_data: -0.7297607032510676, sgn switches: 0\n",
      "step 463 learning rate: 0.82960 loss: 0.24548, accuracy: 88.0%, max_grad: 0.00233, max_grad_neuron: l0n2w0, max_grad_data: -0.7298783129090705, sgn switches: 0\n",
      "step 464 learning rate: 0.83675 loss: 0.24547, accuracy: 88.0%, max_grad: 0.00240, max_grad_neuron: l0n2w0, max_grad_data: -0.7300116189153407, sgn switches: 0\n",
      "step 465 learning rate: 0.84462 loss: 0.24546, accuracy: 88.0%, max_grad: 0.00237, max_grad_neuron: l0n2w0, max_grad_data: -0.7301562859372611, sgn switches: 0\n",
      "step 466 learning rate: 0.85327 loss: 0.24545, accuracy: 88.0%, max_grad: 0.00279, max_grad_neuron: l0n2w0, max_grad_data: -0.7303437300554091, sgn switches: 0\n",
      "step 467 learning rate: 0.85337 loss: 0.24544, accuracy: 88.0%, max_grad: -0.00151, max_grad_neuron: l0n2w1, max_grad_data: 2.39008426510774, sgn switches: 7\n",
      "step 468 learning rate: 0.79078 loss: 0.24543, accuracy: 88.0%, max_grad: 0.01226, max_grad_neuron: l0n2w0, max_grad_data: -0.7314050695911668, sgn switches: 16\n",
      "step 469 learning rate: 0.70993 loss: 0.24545, accuracy: 88.0%, max_grad: -0.04105, max_grad_neuron: l0n2w0, max_grad_data: -0.7297341307926042, sgn switches: 23\n",
      "step 470 learning rate: 0.66161 loss: 0.24546, accuracy: 88.0%, max_grad: 0.05527, max_grad_neuron: l0n2w0, max_grad_data: -0.7308590134099189, sgn switches: 24\n",
      "step 471 learning rate: 0.65458 loss: 0.24541, accuracy: 88.0%, max_grad: 0.00629, max_grad_neuron: l0n2b, max_grad_data: -0.36170260812339017, sgn switches: 9\n",
      "step 472 learning rate: 0.65874 loss: 0.24540, accuracy: 88.0%, max_grad: 0.00608, max_grad_neuron: l0n2b, max_grad_data: -0.3618043671773763, sgn switches: 0\n",
      "step 473 learning rate: 0.66196 loss: 0.24539, accuracy: 88.0%, max_grad: 0.00561, max_grad_neuron: l0n2b, max_grad_data: -0.3619077825938766, sgn switches: 2\n",
      "step 474 learning rate: 0.66686 loss: 0.24538, accuracy: 88.0%, max_grad: 0.00508, max_grad_neuron: l0n2b, max_grad_data: -0.36201079477728737, sgn switches: 0\n",
      "step 475 learning rate: 0.67041 loss: 0.24537, accuracy: 88.0%, max_grad: 0.00457, max_grad_neuron: l0n2b, max_grad_data: -0.3621127781735773, sgn switches: 2\n",
      "step 476 learning rate: 0.67422 loss: 0.24536, accuracy: 88.0%, max_grad: 0.00412, max_grad_neuron: l0n2b, max_grad_data: -0.3622138886472032, sgn switches: 1\n",
      "step 477 learning rate: 0.68035 loss: 0.24535, accuracy: 88.0%, max_grad: 0.00373, max_grad_neuron: l0n2b, max_grad_data: -0.36231463929266516, sgn switches: 0\n",
      "step 478 learning rate: 0.68709 loss: 0.24534, accuracy: 88.0%, max_grad: 0.00340, max_grad_neuron: l0n2b, max_grad_data: -0.3624155994513686, sgn switches: 0\n",
      "step 479 learning rate: 0.69229 loss: 0.24533, accuracy: 88.0%, max_grad: 0.00312, max_grad_neuron: l0n2b, max_grad_data: -0.3625172917016703, sgn switches: 1\n",
      "step 480 learning rate: 0.70023 loss: 0.24532, accuracy: 88.0%, max_grad: 0.00286, max_grad_neuron: l0n2b, max_grad_data: -0.3626201499862878, sgn switches: 0\n",
      "step 481 learning rate: 0.70896 loss: 0.24531, accuracy: 88.0%, max_grad: 0.00264, max_grad_neuron: l0n2b, max_grad_data: -0.3627245337953777, sgn switches: 0\n",
      "step 482 learning rate: 0.71857 loss: 0.24530, accuracy: 88.0%, max_grad: 0.00245, max_grad_neuron: l0n2b, max_grad_data: -0.36283079519718536, sgn switches: 0\n",
      "step 483 learning rate: 0.72914 loss: 0.24529, accuracy: 88.0%, max_grad: 0.00227, max_grad_neuron: l0n2b, max_grad_data: -0.3629392725290107, sgn switches: 0\n",
      "step 484 learning rate: 0.73719 loss: 0.24528, accuracy: 88.0%, max_grad: 0.00211, max_grad_neuron: l0n2b, max_grad_data: -0.3630503182599807, sgn switches: 1\n",
      "step 485 learning rate: 0.74604 loss: 0.24527, accuracy: 88.0%, max_grad: 0.00197, max_grad_neuron: l0n2b, max_grad_data: -0.3631640847217092, sgn switches: 0\n",
      "step 486 learning rate: 0.75058 loss: 0.24526, accuracy: 88.0%, max_grad: 0.00199, max_grad_neuron: l0n2w0, max_grad_data: -0.7313027763679576, sgn switches: 0\n",
      "step 487 learning rate: 0.75467 loss: 0.24525, accuracy: 88.0%, max_grad: 0.00201, max_grad_neuron: l0n2w0, max_grad_data: -0.7313791055684589, sgn switches: 0\n",
      "step 488 learning rate: 0.75917 loss: 0.24524, accuracy: 88.0%, max_grad: 0.00207, max_grad_neuron: l0n2w0, max_grad_data: -0.7314654141983491, sgn switches: 0\n",
      "step 489 learning rate: 0.76411 loss: 0.24523, accuracy: 88.0%, max_grad: 0.00205, max_grad_neuron: l0n2w0, max_grad_data: -0.7315594014802782, sgn switches: 0\n",
      "step 490 learning rate: 0.76956 loss: 0.24521, accuracy: 88.0%, max_grad: 0.00220, max_grad_neuron: l0n2w0, max_grad_data: -0.7316707335708518, sgn switches: 0\n",
      "step 491 learning rate: 0.77555 loss: 0.24520, accuracy: 88.0%, max_grad: 0.00185, max_grad_neuron: l0n2w0, max_grad_data: -0.7317737840167838, sgn switches: 0\n",
      "step 492 learning rate: 0.77865 loss: 0.24519, accuracy: 88.0%, max_grad: 0.00317, max_grad_neuron: l0n2w0, max_grad_data: -0.7319677063550778, sgn switches: 1\n",
      "step 493 learning rate: 0.75750 loss: 0.24518, accuracy: 88.0%, max_grad: -0.00300, max_grad_neuron: l0n2w1, max_grad_data: 2.394947285721495, sgn switches: 12\n",
      "step 494 learning rate: 0.71746 loss: 0.24517, accuracy: 88.0%, max_grad: 0.01728, max_grad_neuron: l0n2w0, max_grad_data: -0.7321740014157823, sgn switches: 20\n",
      "step 495 learning rate: 0.69754 loss: 0.24516, accuracy: 88.0%, max_grad: -0.00910, max_grad_neuron: l0n2w0, max_grad_data: -0.7320829653458407, sgn switches: 20\n",
      "step 496 learning rate: 0.69267 loss: 0.24514, accuracy: 88.0%, max_grad: 0.00553, max_grad_neuron: l0n2b, max_grad_data: -0.36446076414352213, sgn switches: 15\n",
      "step 497 learning rate: 0.69420 loss: 0.24513, accuracy: 88.0%, max_grad: 0.00673, max_grad_neuron: l0n2b, max_grad_data: -0.3645347647277134, sgn switches: 0\n",
      "step 498 learning rate: 0.69587 loss: 0.24512, accuracy: 88.0%, max_grad: 0.00735, max_grad_neuron: l0n2b, max_grad_data: -0.3646236665360549, sgn switches: 0\n",
      "step 499 learning rate: 0.69772 loss: 0.24511, accuracy: 88.0%, max_grad: 0.00753, max_grad_neuron: l0n2b, max_grad_data: -0.36472390590213566, sgn switches: 0\n",
      "step 500 learning rate: 0.69975 loss: 0.24510, accuracy: 88.0%, max_grad: 0.00741, max_grad_neuron: l0n2b, max_grad_data: -0.36483238103227894, sgn switches: 0\n",
      "step 501 learning rate: 0.70198 loss: 0.24508, accuracy: 88.0%, max_grad: 0.00709, max_grad_neuron: l0n2b, max_grad_data: -0.36494663268019617, sgn switches: 0\n",
      "step 502 learning rate: 0.70444 loss: 0.24507, accuracy: 88.0%, max_grad: 0.00668, max_grad_neuron: l0n2b, max_grad_data: -0.3650649573321157, sgn switches: 0\n",
      "step 503 learning rate: 0.70714 loss: 0.24506, accuracy: 88.0%, max_grad: 0.00623, max_grad_neuron: l0n2b, max_grad_data: -0.36518641070248453, sgn switches: 0\n",
      "step 504 learning rate: 0.71011 loss: 0.24505, accuracy: 88.0%, max_grad: 0.00580, max_grad_neuron: l0n2b, max_grad_data: -0.36531069832844976, sgn switches: 0\n",
      "step 505 learning rate: 0.71338 loss: 0.24503, accuracy: 88.0%, max_grad: 0.00540, max_grad_neuron: l0n2b, max_grad_data: -0.36543799109864705, sgn switches: 0\n",
      "step 506 learning rate: 0.71698 loss: 0.24502, accuracy: 88.0%, max_grad: 0.00504, max_grad_neuron: l0n2b, max_grad_data: -0.3655687310090747, sgn switches: 0\n",
      "step 507 learning rate: 0.71934 loss: 0.24501, accuracy: 88.0%, max_grad: 0.00472, max_grad_neuron: l0n2b, max_grad_data: -0.3657034848570872, sgn switches: 1\n",
      "step 508 learning rate: 0.72353 loss: 0.24499, accuracy: 88.0%, max_grad: 0.00444, max_grad_neuron: l0n2b, max_grad_data: -0.3658428688113188, sgn switches: 0\n",
      "step 509 learning rate: 0.72621 loss: 0.24498, accuracy: 88.0%, max_grad: 0.00419, max_grad_neuron: l0n2b, max_grad_data: -0.3659875310609164, sgn switches: 1\n",
      "step 510 learning rate: 0.73109 loss: 0.24496, accuracy: 88.0%, max_grad: 0.00397, max_grad_neuron: l0n2b, max_grad_data: -0.36613815279831696, sgn switches: 0\n",
      "step 511 learning rate: 0.73645 loss: 0.24495, accuracy: 88.0%, max_grad: 0.00377, max_grad_neuron: l0n2b, max_grad_data: -0.3662954736127505, sgn switches: 0\n",
      "step 512 learning rate: 0.74016 loss: 0.24493, accuracy: 88.0%, max_grad: 0.00359, max_grad_neuron: l0n2b, max_grad_data: -0.3664602916117764, sgn switches: 1\n",
      "step 513 learning rate: 0.74643 loss: 0.24492, accuracy: 88.0%, max_grad: 0.00343, max_grad_neuron: l0n2b, max_grad_data: -0.3666335288613315, sgn switches: 0\n",
      "step 514 learning rate: 0.75333 loss: 0.24490, accuracy: 88.0%, max_grad: 0.00328, max_grad_neuron: l0n2b, max_grad_data: -0.36681583929596534, sgn switches: 0\n",
      "step 515 learning rate: 0.76092 loss: 0.24489, accuracy: 88.0%, max_grad: 0.00318, max_grad_neuron: l0n2b, max_grad_data: -0.36701015354414046, sgn switches: 0\n",
      "step 516 learning rate: 0.76927 loss: 0.24487, accuracy: 88.0%, max_grad: 0.00289, max_grad_neuron: l0n2b, max_grad_data: -0.36720487076378333, sgn switches: 0\n",
      "step 517 learning rate: 0.77628 loss: 0.24486, accuracy: 88.0%, max_grad: 0.00528, max_grad_neuron: l0n2w0, max_grad_data: -0.7341021596543063, sgn switches: 1\n",
      "step 518 learning rate: 0.75025 loss: 0.24484, accuracy: 88.0%, max_grad: -0.01369, max_grad_neuron: l0n2w0, max_grad_data: -0.7335956501759126, sgn switches: 15\n",
      "step 519 learning rate: 0.67351 loss: 0.24500, accuracy: 88.0%, max_grad: 0.10941, max_grad_neuron: l0n2w0, max_grad_data: -0.7356197955042301, sgn switches: 25\n",
      "step 520 learning rate: 0.61911 loss: 0.24604, accuracy: 88.0%, max_grad: -0.34943, max_grad_neuron: l0n2w0, max_grad_data: -0.7321254470825493, sgn switches: 27\n",
      "step 521 learning rate: 0.45413 loss: 0.24660, accuracy: 88.0%, max_grad: 0.25945, max_grad_neuron: l0n2w0, max_grad_data: -0.7347199470564224, sgn switches: 32\n",
      "step 522 learning rate: 0.40013 loss: 0.24551, accuracy: 88.0%, max_grad: 0.12615, max_grad_neuron: l0n2w0, max_grad_data: -0.7361075494994769, sgn switches: 25\n",
      "step 523 learning rate: 0.38402 loss: 0.24502, accuracy: 88.0%, max_grad: 0.09279, max_grad_neuron: l0n2b, max_grad_data: -0.3670647924808837, sgn switches: 6\n",
      "step 524 learning rate: 0.36774 loss: 0.24485, accuracy: 88.0%, max_grad: 0.06444, max_grad_neuron: l0n2b, max_grad_data: -0.3678444877886824, sgn switches: 14\n",
      "step 525 learning rate: 0.37561 loss: 0.24479, accuracy: 88.0%, max_grad: 0.04024, max_grad_neuron: l0n2b, max_grad_data: -0.36838010296514806, sgn switches: 3\n",
      "step 526 learning rate: 0.38560 loss: 0.24476, accuracy: 88.0%, max_grad: 0.02312, max_grad_neuron: l0n2b, max_grad_data: -0.3687186307314797, sgn switches: 2\n",
      "step 527 learning rate: 0.39713 loss: 0.24475, accuracy: 88.0%, max_grad: 0.01172, max_grad_neuron: l0n2b, max_grad_data: -0.3689074138774241, sgn switches: 3\n",
      "step 528 learning rate: 0.41250 loss: 0.24474, accuracy: 88.0%, max_grad: 0.00623, max_grad_neuron: l0n2b, max_grad_data: -0.36901773479295774, sgn switches: 2\n",
      "step 529 learning rate: 0.42810 loss: 0.24473, accuracy: 88.0%, max_grad: 0.00417, max_grad_neuron: l0n2b, max_grad_data: -0.36909905301730195, sgn switches: 4\n",
      "step 530 learning rate: 0.44654 loss: 0.24472, accuracy: 88.0%, max_grad: 0.00358, max_grad_neuron: l0n2b, max_grad_data: -0.3691757418352527, sgn switches: 1\n",
      "step 531 learning rate: 0.46700 loss: 0.24471, accuracy: 88.0%, max_grad: 0.00332, max_grad_neuron: l0n2b, max_grad_data: -0.3692539453939022, sgn switches: 0\n",
      "step 532 learning rate: 0.48950 loss: 0.24470, accuracy: 88.0%, max_grad: 0.00338, max_grad_neuron: l0n2w0, max_grad_data: -0.7360683941863372, sgn switches: 0\n",
      "step 533 learning rate: 0.51426 loss: 0.24469, accuracy: 88.0%, max_grad: 0.00338, max_grad_neuron: l0n2w0, max_grad_data: -0.7361227839519567, sgn switches: 0\n",
      "step 534 learning rate: 0.54149 loss: 0.24468, accuracy: 88.0%, max_grad: 0.00345, max_grad_neuron: l0n2w0, max_grad_data: -0.736183832356358, sgn switches: 0\n",
      "step 535 learning rate: 0.57145 loss: 0.24466, accuracy: 88.0%, max_grad: 0.00342, max_grad_neuron: l0n2w0, max_grad_data: -0.7362505663247042, sgn switches: 0\n",
      "step 536 learning rate: 0.60368 loss: 0.24465, accuracy: 88.0%, max_grad: 0.00354, max_grad_neuron: l0n2w0, max_grad_data: -0.7363264865540579, sgn switches: 0\n",
      "step 537 learning rate: 0.62538 loss: 0.24463, accuracy: 88.0%, max_grad: 0.00341, max_grad_neuron: l0n2w0, max_grad_data: -0.7364068321794339, sgn switches: 0\n",
      "step 538 learning rate: 0.63165 loss: 0.24461, accuracy: 88.0%, max_grad: 0.00380, max_grad_neuron: l0n2w0, max_grad_data: -0.736505324022547, sgn switches: 0\n",
      "step 539 learning rate: 0.63601 loss: 0.24459, accuracy: 88.0%, max_grad: 0.00289, max_grad_neuron: l0n2w0, max_grad_data: -0.7365876759434516, sgn switches: 2\n",
      "step 540 learning rate: 0.63062 loss: 0.24458, accuracy: 88.0%, max_grad: 0.00594, max_grad_neuron: l0n2w0, max_grad_data: -0.736774219471133, sgn switches: 8\n",
      "step 541 learning rate: 0.62450 loss: 0.24456, accuracy: 88.0%, max_grad: -0.00576, max_grad_neuron: l0n2b, max_grad_data: -0.37028081927138595, sgn switches: 18\n",
      "step 542 learning rate: 0.62279 loss: 0.24454, accuracy: 88.0%, max_grad: 0.01249, max_grad_neuron: l0n2b, max_grad_data: -0.37045441955188413, sgn switches: 19\n",
      "step 543 learning rate: 0.62555 loss: 0.24452, accuracy: 88.0%, max_grad: 0.00703, max_grad_neuron: l0n2b, max_grad_data: -0.3705619522393731, sgn switches: 4\n",
      "step 544 learning rate: 0.63001 loss: 0.24450, accuracy: 88.0%, max_grad: 0.00626, max_grad_neuron: l0n2b, max_grad_data: -0.370667163751605, sgn switches: 1\n",
      "step 545 learning rate: 0.63495 loss: 0.24449, accuracy: 88.0%, max_grad: 0.00577, max_grad_neuron: l0n2b, max_grad_data: -0.3707738405321786, sgn switches: 0\n",
      "step 546 learning rate: 0.64038 loss: 0.24447, accuracy: 88.0%, max_grad: 0.00530, max_grad_neuron: l0n2b, max_grad_data: -0.3708816835054394, sgn switches: 0\n",
      "step 547 learning rate: 0.64625 loss: 0.24445, accuracy: 88.0%, max_grad: 0.00486, max_grad_neuron: l0n2b, max_grad_data: -0.3709905722795736, sgn switches: 1\n",
      "step 548 learning rate: 0.65281 loss: 0.24443, accuracy: 88.0%, max_grad: 0.00447, max_grad_neuron: l0n2b, max_grad_data: -0.37110067243241684, sgn switches: 0\n",
      "step 549 learning rate: 0.65972 loss: 0.24441, accuracy: 88.0%, max_grad: 0.00412, max_grad_neuron: l0n2b, max_grad_data: -0.3712122188754767, sgn switches: 2\n",
      "step 550 learning rate: 0.66763 loss: 0.24439, accuracy: 88.0%, max_grad: 0.00380, max_grad_neuron: l0n2b, max_grad_data: -0.3713254691331281, sgn switches: 0\n",
      "step 551 learning rate: 0.67633 loss: 0.24437, accuracy: 88.0%, max_grad: 0.00352, max_grad_neuron: l0n2b, max_grad_data: -0.37144068471582814, sgn switches: 0\n",
      "step 552 learning rate: 0.68005 loss: 0.24435, accuracy: 88.0%, max_grad: 0.00326, max_grad_neuron: l0n2b, max_grad_data: -0.371558150232617, sgn switches: 0\n",
      "step 553 learning rate: 0.68208 loss: 0.24433, accuracy: 88.0%, max_grad: 0.00299, max_grad_neuron: l0n2b, max_grad_data: -0.37167658927150105, sgn switches: 0\n",
      "step 554 learning rate: 0.68416 loss: 0.24431, accuracy: 88.0%, max_grad: 0.00280, max_grad_neuron: l0n2b, max_grad_data: -0.3717986518211477, sgn switches: 0\n",
      "step 555 learning rate: 0.68645 loss: 0.24429, accuracy: 88.0%, max_grad: 0.00252, max_grad_neuron: l0n2b, max_grad_data: -0.3719194691554159, sgn switches: 0\n",
      "step 556 learning rate: 0.68896 loss: 0.24427, accuracy: 88.0%, max_grad: 0.00252, max_grad_neuron: l0n2b, max_grad_data: -0.3720522356381174, sgn switches: 0\n",
      "step 557 learning rate: 0.69136 loss: 0.24424, accuracy: 88.0%, max_grad: -0.00219, max_grad_neuron: l0n2w1, max_grad_data: 2.409627513095599, sgn switches: 1\n",
      "step 558 learning rate: 0.69419 loss: 0.24422, accuracy: 88.0%, max_grad: 0.00332, max_grad_neuron: l0n2b, max_grad_data: -0.37237116037340573, sgn switches: 1\n",
      "step 559 learning rate: 0.69046 loss: 0.24420, accuracy: 88.0%, max_grad: -0.00361, max_grad_neuron: l0n2w1, max_grad_data: 2.410086685162396, sgn switches: 11\n",
      "step 560 learning rate: 0.67724 loss: 0.24418, accuracy: 88.0%, max_grad: 0.01458, max_grad_neuron: l0n2b, max_grad_data: -0.37251150503962627, sgn switches: 20\n",
      "step 561 learning rate: 0.67344 loss: 0.24416, accuracy: 88.0%, max_grad: 0.00316, max_grad_neuron: l0n2b, max_grad_data: -0.37256703196826335, sgn switches: 10\n",
      "step 562 learning rate: 0.67620 loss: 0.24413, accuracy: 88.0%, max_grad: 0.00673, max_grad_neuron: l0n2b, max_grad_data: -0.37269707320258116, sgn switches: 4\n",
      "step 563 learning rate: 0.67927 loss: 0.24411, accuracy: 88.0%, max_grad: 0.00445, max_grad_neuron: l0n2b, max_grad_data: -0.37279162228995155, sgn switches: 2\n",
      "step 564 learning rate: 0.68265 loss: 0.24409, accuracy: 88.0%, max_grad: 0.00514, max_grad_neuron: l0n2b, max_grad_data: -0.3729116708636115, sgn switches: 2\n",
      "step 565 learning rate: 0.68632 loss: 0.24407, accuracy: 88.0%, max_grad: 0.00386, max_grad_neuron: l0n2b, max_grad_data: -0.3730108917299535, sgn switches: 3\n",
      "step 566 learning rate: 0.69041 loss: 0.24404, accuracy: 88.0%, max_grad: 0.00444, max_grad_neuron: l0n2b, max_grad_data: -0.3731363464881009, sgn switches: 1\n",
      "step 567 learning rate: 0.69378 loss: 0.24402, accuracy: 88.0%, max_grad: 0.00296, max_grad_neuron: l0n2b, max_grad_data: -0.3732284612717558, sgn switches: 1\n",
      "step 568 learning rate: 0.69540 loss: 0.24400, accuracy: 88.0%, max_grad: 0.00447, max_grad_neuron: l0n2b, max_grad_data: -0.37338152254362944, sgn switches: 1\n",
      "step 569 learning rate: 0.68777 loss: 0.24397, accuracy: 88.0%, max_grad: -0.00272, max_grad_neuron: l0n2w1, max_grad_data: 2.4105790137969674, sgn switches: 7\n",
      "step 570 learning rate: 0.68973 loss: 0.24395, accuracy: 88.0%, max_grad: 0.00781, max_grad_neuron: l0n2b, max_grad_data: -0.37373937931669304, sgn switches: 8\n",
      "step 571 learning rate: 0.68939 loss: 0.24393, accuracy: 88.0%, max_grad: -0.00947, max_grad_neuron: l0n2b, max_grad_data: -0.3735433726376119, sgn switches: 14\n",
      "step 572 learning rate: 0.68192 loss: 0.24390, accuracy: 88.0%, max_grad: 0.01929, max_grad_neuron: l0n2b, max_grad_data: -0.37374314704849476, sgn switches: 20\n",
      "step 573 learning rate: 0.67967 loss: 0.24388, accuracy: 88.0%, max_grad: 0.00844, max_grad_neuron: l0n2b, max_grad_data: -0.3738392884436903, sgn switches: 7\n",
      "step 574 learning rate: 0.68149 loss: 0.24385, accuracy: 88.0%, max_grad: 0.00832, max_grad_neuron: l0n2b, max_grad_data: -0.37394347242537807, sgn switches: 1\n",
      "step 575 learning rate: 0.68351 loss: 0.24383, accuracy: 88.0%, max_grad: 0.00752, max_grad_neuron: l0n2b, max_grad_data: -0.3740471418033322, sgn switches: 0\n",
      "step 576 learning rate: 0.68573 loss: 0.24380, accuracy: 88.0%, max_grad: 0.00688, max_grad_neuron: l0n2b, max_grad_data: -0.37415138966481093, sgn switches: 0\n",
      "step 577 learning rate: 0.68702 loss: 0.24378, accuracy: 88.0%, max_grad: 0.00628, max_grad_neuron: l0n2b, max_grad_data: -0.3742560513815305, sgn switches: 0\n",
      "step 578 learning rate: 0.68798 loss: 0.24375, accuracy: 88.0%, max_grad: 0.00575, max_grad_neuron: l0n2b, max_grad_data: -0.3743614400832021, sgn switches: 0\n",
      "step 579 learning rate: 0.68904 loss: 0.24373, accuracy: 88.0%, max_grad: 0.00526, max_grad_neuron: l0n2b, max_grad_data: -0.37446761753868885, sgn switches: 0\n",
      "step 580 learning rate: 0.68983 loss: 0.24370, accuracy: 88.0%, max_grad: 0.00483, max_grad_neuron: l0n2b, max_grad_data: -0.37457484807766017, sgn switches: 2\n",
      "step 581 learning rate: 0.69107 loss: 0.24367, accuracy: 88.0%, max_grad: 0.00444, max_grad_neuron: l0n2b, max_grad_data: -0.3746831964345695, sgn switches: 0\n",
      "step 582 learning rate: 0.69221 loss: 0.24365, accuracy: 88.0%, max_grad: 0.00409, max_grad_neuron: l0n2b, max_grad_data: -0.374793006219939, sgn switches: 1\n",
      "step 583 learning rate: 0.69369 loss: 0.24362, accuracy: 88.0%, max_grad: 0.00376, max_grad_neuron: l0n2b, max_grad_data: -0.3749041979121927, sgn switches: 0\n",
      "step 584 learning rate: 0.69531 loss: 0.24359, accuracy: 88.0%, max_grad: 0.00349, max_grad_neuron: l0n2b, max_grad_data: -0.3750175728086177, sgn switches: 0\n",
      "step 585 learning rate: 0.69710 loss: 0.24357, accuracy: 88.0%, max_grad: 0.00320, max_grad_neuron: l0n2b, max_grad_data: -0.37513188552788046, sgn switches: 0\n",
      "step 586 learning rate: 0.69907 loss: 0.24354, accuracy: 88.0%, max_grad: 0.00305, max_grad_neuron: l0n2b, max_grad_data: -0.3752517453185087, sgn switches: 0\n",
      "step 587 learning rate: 0.70123 loss: 0.24351, accuracy: 88.0%, max_grad: -0.00259, max_grad_neuron: l0n2w1, max_grad_data: 2.4118294874441735, sgn switches: 0\n",
      "step 588 learning rate: 0.70362 loss: 0.24348, accuracy: 88.0%, max_grad: 0.00339, max_grad_neuron: l0n2b, max_grad_data: -0.37552371105975313, sgn switches: 0\n",
      "step 589 learning rate: 0.70080 loss: 0.24345, accuracy: 88.0%, max_grad: -0.00370, max_grad_neuron: l0n2w1, max_grad_data: 2.412212404957717, sgn switches: 10\n",
      "step 590 learning rate: 0.69018 loss: 0.24343, accuracy: 88.0%, max_grad: 0.01599, max_grad_neuron: l0n2b, max_grad_data: -0.3756866990873926, sgn switches: 18\n",
      "step 591 learning rate: 0.68594 loss: 0.24340, accuracy: 88.0%, max_grad: 0.00364, max_grad_neuron: l0n2b, max_grad_data: -0.3757343681158042, sgn switches: 11\n",
      "step 592 learning rate: 0.68644 loss: 0.24337, accuracy: 88.0%, max_grad: 0.00933, max_grad_neuron: l0n2b, max_grad_data: -0.37586867057764856, sgn switches: 6\n",
      "step 593 learning rate: 0.68732 loss: 0.24334, accuracy: 88.0%, max_grad: 0.00476, max_grad_neuron: l0n2b, max_grad_data: -0.3759440957250028, sgn switches: 2\n",
      "step 594 learning rate: 0.68827 loss: 0.24331, accuracy: 88.0%, max_grad: 0.00729, max_grad_neuron: l0n2b, max_grad_data: -0.37607097186229177, sgn switches: 2\n",
      "step 595 learning rate: 0.68927 loss: 0.24328, accuracy: 88.0%, max_grad: 0.00376, max_grad_neuron: l0n2b, max_grad_data: -0.3761430098517553, sgn switches: 3\n",
      "step 596 learning rate: 0.69041 loss: 0.24325, accuracy: 88.0%, max_grad: 0.00705, max_grad_neuron: l0n2b, max_grad_data: -0.37629148320918576, sgn switches: 3\n",
      "step 597 learning rate: 0.69097 loss: 0.24322, accuracy: 88.0%, max_grad: -0.00307, max_grad_neuron: l0n2w1, max_grad_data: 2.412496215344593, sgn switches: 7\n",
      "step 598 learning rate: 0.68901 loss: 0.24319, accuracy: 88.0%, max_grad: 0.01058, max_grad_neuron: l0n2b, max_grad_data: -0.3765867326801505, sgn switches: 8\n",
      "step 599 learning rate: 0.68631 loss: 0.24316, accuracy: 88.0%, max_grad: -0.01019, max_grad_neuron: l0n2b, max_grad_data: -0.37645685015539504, sgn switches: 15\n",
      "step 600 learning rate: 0.68430 loss: 0.24313, accuracy: 88.0%, max_grad: 0.02082, max_grad_neuron: l0n2b, max_grad_data: -0.3766650827055673, sgn switches: 19\n",
      "step 601 learning rate: 0.68403 loss: 0.24310, accuracy: 88.0%, max_grad: 0.00505, max_grad_neuron: l0n2b, max_grad_data: -0.3767205802222273, sgn switches: 8\n",
      "step 602 learning rate: 0.68445 loss: 0.24307, accuracy: 88.0%, max_grad: 0.00983, max_grad_neuron: l0n2b, max_grad_data: -0.37683949353788976, sgn switches: 4\n",
      "step 603 learning rate: 0.68513 loss: 0.24304, accuracy: 88.0%, max_grad: 0.00639, max_grad_neuron: l0n2b, max_grad_data: -0.37692460033639513, sgn switches: 1\n",
      "step 604 learning rate: 0.68590 loss: 0.24301, accuracy: 88.0%, max_grad: 0.00750, max_grad_neuron: l0n2b, max_grad_data: -0.37703436329387086, sgn switches: 0\n",
      "step 605 learning rate: 0.68669 loss: 0.24298, accuracy: 88.0%, max_grad: 0.00544, max_grad_neuron: l0n2b, max_grad_data: -0.3771219666352659, sgn switches: 1\n",
      "step 606 learning rate: 0.68760 loss: 0.24295, accuracy: 88.0%, max_grad: 0.00648, max_grad_neuron: l0n2b, max_grad_data: -0.37723672929119234, sgn switches: 1\n",
      "step 607 learning rate: 0.68845 loss: 0.24292, accuracy: 88.0%, max_grad: 0.00397, max_grad_neuron: l0n2b, max_grad_data: -0.37731402613051096, sgn switches: 2\n",
      "step 608 learning rate: 0.68952 loss: 0.24288, accuracy: 88.0%, max_grad: 0.00673, max_grad_neuron: l0n2b, max_grad_data: -0.3774583952682187, sgn switches: 2\n",
      "step 609 learning rate: 0.68930 loss: 0.24285, accuracy: 88.0%, max_grad: -0.00354, max_grad_neuron: l0n2w1, max_grad_data: 2.413005109528625, sgn switches: 9\n",
      "step 610 learning rate: 0.69012 loss: 0.24282, accuracy: 88.0%, max_grad: 0.01301, max_grad_neuron: l0n2b, max_grad_data: -0.37780438090817, sgn switches: 10\n",
      "step 611 learning rate: 0.68976 loss: 0.24279, accuracy: 89.0%, max_grad: -0.01828, max_grad_neuron: l0n2b, max_grad_data: -0.3775672524387561, sgn switches: 15\n",
      "step 612 learning rate: 0.67657 loss: 0.24276, accuracy: 88.0%, max_grad: 0.03151, max_grad_neuron: l0n2b, max_grad_data: -0.3778823497810332, sgn switches: 21\n",
      "step 613 learning rate: 0.67034 loss: 0.24272, accuracy: 89.0%, max_grad: -0.00476, max_grad_neuron: l0n2w1, max_grad_data: 2.4132140874770043, sgn switches: 21\n",
      "step 614 learning rate: 0.67101 loss: 0.24269, accuracy: 88.0%, max_grad: 0.01438, max_grad_neuron: l0n2b, max_grad_data: -0.3780053622922507, sgn switches: 15\n",
      "step 615 learning rate: 0.67195 loss: 0.24266, accuracy: 89.0%, max_grad: 0.00614, max_grad_neuron: l0n2b, max_grad_data: -0.3780728775375623, sgn switches: 2\n",
      "step 616 learning rate: 0.67298 loss: 0.24262, accuracy: 89.0%, max_grad: 0.00962, max_grad_neuron: l0n2b, max_grad_data: -0.3781893058325624, sgn switches: 2\n",
      "step 617 learning rate: 0.67412 loss: 0.24259, accuracy: 89.0%, max_grad: 0.00574, max_grad_neuron: l0n2b, max_grad_data: -0.3782657087689018, sgn switches: 2\n",
      "step 618 learning rate: 0.67537 loss: 0.24256, accuracy: 89.0%, max_grad: 0.00822, max_grad_neuron: l0n2b, max_grad_data: -0.37838610590852767, sgn switches: 2\n",
      "step 619 learning rate: 0.66848 loss: 0.24252, accuracy: 89.0%, max_grad: 0.00398, max_grad_neuron: l0n2b, max_grad_data: -0.3784502517964838, sgn switches: 5\n",
      "step 620 learning rate: 0.67075 loss: 0.24249, accuracy: 89.0%, max_grad: 0.00884, max_grad_neuron: l0n2b, max_grad_data: -0.378606795667367, sgn switches: 4\n",
      "step 621 learning rate: 0.67186 loss: 0.24245, accuracy: 89.0%, max_grad: -0.00417, max_grad_neuron: l0n2w1, max_grad_data: 2.4135112519887065, sgn switches: 13\n",
      "step 622 learning rate: 0.67370 loss: 0.24242, accuracy: 89.0%, max_grad: 0.01624, max_grad_neuron: l0n2b, max_grad_data: -0.37876021339158494, sgn switches: 16\n",
      "step 623 learning rate: 0.67639 loss: 0.24238, accuracy: 89.0%, max_grad: 0.00339, max_grad_neuron: l0n2b, max_grad_data: -0.3787974767057195, sgn switches: 8\n",
      "step 624 learning rate: 0.67943 loss: 0.24235, accuracy: 89.0%, max_grad: 0.01194, max_grad_neuron: l0n2b, max_grad_data: -0.3789419210231818, sgn switches: 5\n",
      "step 625 learning rate: 0.68278 loss: 0.24231, accuracy: 89.0%, max_grad: -0.00348, max_grad_neuron: l0n2w1, max_grad_data: 2.4135958584367554, sgn switches: 5\n",
      "step 626 learning rate: 0.68646 loss: 0.24228, accuracy: 89.0%, max_grad: 0.01234, max_grad_neuron: l0n2b, max_grad_data: -0.37915445223165684, sgn switches: 5\n",
      "step 627 learning rate: 0.68796 loss: 0.24224, accuracy: 89.0%, max_grad: -0.00484, max_grad_neuron: l0n2w1, max_grad_data: 2.413680319375641, sgn switches: 15\n",
      "step 628 learning rate: 0.68917 loss: 0.24221, accuracy: 89.0%, max_grad: 0.01874, max_grad_neuron: l0n2b, max_grad_data: -0.37930821066219683, sgn switches: 18\n",
      "step 629 learning rate: 0.69013 loss: 0.24217, accuracy: 89.0%, max_grad: -0.00395, max_grad_neuron: l0n2w1, max_grad_data: 2.413713755929537, sgn switches: 13\n",
      "step 630 learning rate: 0.69124 loss: 0.24213, accuracy: 89.0%, max_grad: 0.01492, max_grad_neuron: l0n2b, max_grad_data: -0.3795003047054516, sgn switches: 10\n",
      "step 631 learning rate: 0.69227 loss: 0.24210, accuracy: 89.0%, max_grad: -0.00423, max_grad_neuron: l0n2w1, max_grad_data: 2.4137706016438254, sgn switches: 13\n",
      "step 632 learning rate: 0.69344 loss: 0.24206, accuracy: 89.0%, max_grad: 0.01727, max_grad_neuron: l0n2b, max_grad_data: -0.37966200894439456, sgn switches: 15\n",
      "step 633 learning rate: 0.69474 loss: 0.24203, accuracy: 89.0%, max_grad: -0.00409, max_grad_neuron: l0n2w1, max_grad_data: 2.413811021204425, sgn switches: 11\n",
      "step 634 learning rate: 0.69633 loss: 0.24199, accuracy: 89.0%, max_grad: 0.01517, max_grad_neuron: l0n2b, max_grad_data: -0.3798609549056158, sgn switches: 9\n",
      "step 635 learning rate: 0.69779 loss: 0.24195, accuracy: 89.0%, max_grad: -0.00459, max_grad_neuron: l0n2w1, max_grad_data: 2.4138718424066603, sgn switches: 13\n",
      "step 636 learning rate: 0.69796 loss: 0.24191, accuracy: 89.0%, max_grad: 0.01939, max_grad_neuron: l0n2b, max_grad_data: -0.38002885842638967, sgn switches: 16\n",
      "step 637 learning rate: 0.69804 loss: 0.24188, accuracy: 89.0%, max_grad: -0.00483, max_grad_neuron: l0n2w1, max_grad_data: 2.413915191362915, sgn switches: 18\n",
      "step 638 learning rate: 0.69820 loss: 0.24184, accuracy: 89.0%, max_grad: 0.01868, max_grad_neuron: l0n2b, max_grad_data: -0.38020083028772533, sgn switches: 18\n",
      "step 639 learning rate: 0.69839 loss: 0.24180, accuracy: 89.0%, max_grad: -0.00455, max_grad_neuron: l0n2w1, max_grad_data: 2.4139576808024126, sgn switches: 17\n",
      "step 640 learning rate: 0.69860 loss: 0.24176, accuracy: 89.0%, max_grad: 0.01871, max_grad_neuron: l0n2b, max_grad_data: -0.3803750881730133, sgn switches: 17\n",
      "step 641 learning rate: 0.69883 loss: 0.24173, accuracy: 89.0%, max_grad: -0.00468, max_grad_neuron: l0n2w1, max_grad_data: 2.4140022164062835, sgn switches: 17\n",
      "step 642 learning rate: 0.69909 loss: 0.24169, accuracy: 89.0%, max_grad: 0.01961, max_grad_neuron: l0n2b, max_grad_data: -0.3805531337457516, sgn switches: 17\n",
      "step 643 learning rate: 0.69927 loss: 0.24165, accuracy: 89.0%, max_grad: -0.00504, max_grad_neuron: l0n2w1, max_grad_data: 2.414048663237615, sgn switches: 18\n",
      "step 644 learning rate: 0.69955 loss: 0.24161, accuracy: 89.0%, max_grad: 0.02165, max_grad_neuron: l0n2b, max_grad_data: -0.3807364612639, sgn switches: 18\n",
      "step 645 learning rate: 0.69986 loss: 0.24157, accuracy: 89.0%, max_grad: -0.00619, max_grad_neuron: l0n2b, max_grad_data: -0.3806745219669933, sgn switches: 18\n",
      "step 646 learning rate: 0.70020 loss: 0.24153, accuracy: 89.0%, max_grad: 0.02538, max_grad_neuron: l0n2b, max_grad_data: -0.38092831687177364, sgn switches: 18\n",
      "step 647 learning rate: 0.70057 loss: 0.24150, accuracy: 89.0%, max_grad: -0.01127, max_grad_neuron: l0n2b, max_grad_data: -0.3808156085211566, sgn switches: 18\n",
      "step 648 learning rate: 0.69045 loss: 0.24146, accuracy: 89.0%, max_grad: 0.03197, max_grad_neuron: l0n2b, max_grad_data: -0.3811352654482844, sgn switches: 20\n",
      "step 649 learning rate: 0.68538 loss: 0.24142, accuracy: 89.0%, max_grad: -0.02019, max_grad_neuron: l0n2b, max_grad_data: -0.3809333650347303, sgn switches: 20\n",
      "step 650 learning rate: 0.68285 loss: 0.24138, accuracy: 89.0%, max_grad: 0.04306, max_grad_neuron: l0n2b, max_grad_data: -0.3813639704247795, sgn switches: 20\n",
      "step 651 learning rate: 0.68159 loss: 0.24134, accuracy: 89.0%, max_grad: -0.03539, max_grad_neuron: l0n2b, max_grad_data: -0.381010051381939, sgn switches: 20\n",
      "step 652 learning rate: 0.67292 loss: 0.24131, accuracy: 89.0%, max_grad: 0.06298, max_grad_neuron: l0n2b, max_grad_data: -0.38163987870135896, sgn switches: 21\n",
      "step 653 learning rate: 0.66864 loss: 0.24127, accuracy: 89.0%, max_grad: -0.06338, max_grad_neuron: l0n2b, max_grad_data: -0.38100611633230413, sgn switches: 21\n",
      "step 654 learning rate: 0.65847 loss: 0.24124, accuracy: 89.0%, max_grad: 0.09994, max_grad_neuron: l0n2b, max_grad_data: -0.38200547017209446, sgn switches: 22\n",
      "step 655 learning rate: 0.65343 loss: 0.24122, accuracy: 89.0%, max_grad: -0.11690, max_grad_neuron: l0n2b, max_grad_data: -0.3808364896319, sgn switches: 22\n",
      "step 656 learning rate: 0.62671 loss: 0.24122, accuracy: 89.0%, max_grad: 0.16907, max_grad_neuron: l0n2b, max_grad_data: -0.3825271756440868, sgn switches: 25\n",
      "step 657 learning rate: 0.59723 loss: 0.24122, accuracy: 89.0%, max_grad: -0.21906, max_grad_neuron: l0n2b, max_grad_data: -0.3803365723470352, sgn switches: 27\n",
      "step 658 learning rate: 0.58252 loss: 0.24131, accuracy: 89.0%, max_grad: 0.27346, max_grad_neuron: l0n2b, max_grad_data: -0.3830712053642663, sgn switches: 27\n",
      "step 659 learning rate: 0.56715 loss: 0.24132, accuracy: 89.0%, max_grad: -0.35709, max_grad_neuron: l0n2b, max_grad_data: -0.3795002921367055, sgn switches: 28\n",
      "step 660 learning rate: 0.55143 loss: 0.24162, accuracy: 88.0%, max_grad: 0.39612, max_grad_neuron: l0n2b, max_grad_data: -0.3834614445691241, sgn switches: 29\n",
      "step 661 learning rate: 0.54362 loss: 0.24142, accuracy: 89.0%, max_grad: -0.46372, max_grad_neuron: l0n2b, max_grad_data: -0.37882427641626853, sgn switches: 29\n",
      "step 662 learning rate: 0.49950 loss: 0.24196, accuracy: 88.0%, max_grad: 0.46634, max_grad_neuron: l0n2b, max_grad_data: -0.38348769335909005, sgn switches: 34\n",
      "step 663 learning rate: 0.47764 loss: 0.24136, accuracy: 89.0%, max_grad: -0.45890, max_grad_neuron: l0n2b, max_grad_data: -0.378898694803399, sgn switches: 34\n",
      "step 664 learning rate: 0.46680 loss: 0.24190, accuracy: 88.0%, max_grad: 0.47074, max_grad_neuron: l0n2b, max_grad_data: -0.38360604807035564, sgn switches: 34\n",
      "step 665 learning rate: 0.46142 loss: 0.24135, accuracy: 89.0%, max_grad: -0.48776, max_grad_neuron: l0n2b, max_grad_data: -0.3787284764059138, sgn switches: 34\n",
      "step 666 learning rate: 0.45881 loss: 0.24199, accuracy: 88.0%, max_grad: 0.49121, max_grad_neuron: l0n2b, max_grad_data: -0.38364056864660345, sgn switches: 34\n",
      "step 667 learning rate: 0.45755 loss: 0.24130, accuracy: 89.0%, max_grad: -0.48864, max_grad_neuron: l0n2b, max_grad_data: -0.37875420293906803, sgn switches: 34\n",
      "step 668 learning rate: 0.44903 loss: 0.24197, accuracy: 88.0%, max_grad: 0.49858, max_grad_neuron: l0n2b, max_grad_data: -0.3837399964273136, sgn switches: 35\n",
      "step 669 learning rate: 0.44500 loss: 0.24129, accuracy: 89.0%, max_grad: -0.51228, max_grad_neuron: l0n2b, max_grad_data: -0.3786172053158633, sgn switches: 35\n",
      "step 670 learning rate: 0.43492 loss: 0.24205, accuracy: 88.0%, max_grad: 0.51480, max_grad_neuron: l0n2b, max_grad_data: -0.38376518625524625, sgn switches: 36\n",
      "step 671 learning rate: 0.42988 loss: 0.24124, accuracy: 89.0%, max_grad: -0.51096, max_grad_neuron: l0n2b, max_grad_data: -0.378655594310413, sgn switches: 36\n",
      "step 672 learning rate: 0.42736 loss: 0.24202, accuracy: 88.0%, max_grad: 0.52037, max_grad_neuron: l0n2b, max_grad_data: -0.3838592673734176, sgn switches: 36\n",
      "step 673 learning rate: 0.42610 loss: 0.24124, accuracy: 89.0%, max_grad: -0.53509, max_grad_neuron: l0n2b, max_grad_data: -0.3785083729361091, sgn switches: 36\n",
      "step 674 learning rate: 0.41744 loss: 0.24211, accuracy: 88.0%, max_grad: 0.53481, max_grad_neuron: l0n2b, max_grad_data: -0.3838564923127481, sgn switches: 37\n",
      "step 675 learning rate: 0.41317 loss: 0.24118, accuracy: 89.0%, max_grad: -0.52552, max_grad_neuron: l0n2b, max_grad_data: -0.37860128634382517, sgn switches: 36\n",
      "step 676 learning rate: 0.41108 loss: 0.24204, accuracy: 88.0%, max_grad: 0.53765, max_grad_neuron: l0n2b, max_grad_data: -0.38397778889862316, sgn switches: 36\n",
      "step 677 learning rate: 0.41004 loss: 0.24120, accuracy: 89.0%, max_grad: -0.56045, max_grad_neuron: l0n2b, max_grad_data: -0.37837329318041185, sgn switches: 37\n",
      "step 678 learning rate: 0.40147 loss: 0.24219, accuracy: 88.0%, max_grad: 0.55399, max_grad_neuron: l0n2b, max_grad_data: -0.383913181791638, sgn switches: 38\n",
      "step 679 learning rate: 0.39722 loss: 0.24110, accuracy: 89.0%, max_grad: -0.52886, max_grad_neuron: l0n2b, max_grad_data: -0.37862453236202526, sgn switches: 36\n",
      "step 680 learning rate: 0.39757 loss: 0.24202, accuracy: 88.0%, max_grad: 0.55066, max_grad_neuron: l0n2b, max_grad_data: -0.3841311267269769, sgn switches: 35\n",
      "step 681 learning rate: 0.39794 loss: 0.24119, accuracy: 89.0%, max_grad: -0.59989, max_grad_neuron: l0n2b, max_grad_data: -0.3781322282056874, sgn switches: 37\n",
      "step 682 learning rate: 0.37131 loss: 0.24235, accuracy: 88.0%, max_grad: 0.57363, max_grad_neuron: l0n2b, max_grad_data: -0.383868492132687, sgn switches: 41\n",
      "step 683 learning rate: 0.35804 loss: 0.24096, accuracy: 89.0%, max_grad: -0.49621, max_grad_neuron: l0n2b, max_grad_data: -0.37890639766169615, sgn switches: 38\n",
      "step 684 learning rate: 0.35943 loss: 0.24183, accuracy: 88.0%, max_grad: 0.54886, max_grad_neuron: l0n2b, max_grad_data: -0.38439500860963843, sgn switches: 34\n",
      "step 685 learning rate: 0.36079 loss: 0.24128, accuracy: 89.0%, max_grad: -0.68455, max_grad_neuron: l0n2b, max_grad_data: -0.3775495352976908, sgn switches: 37\n",
      "step 686 learning rate: 0.33660 loss: 0.24277, accuracy: 88.0%, max_grad: 0.58694, max_grad_neuron: l0n2b, max_grad_data: -0.38341894069766713, sgn switches: 43\n",
      "step 687 learning rate: 0.32461 loss: 0.24065, accuracy: 89.0%, max_grad: -0.32653, max_grad_neuron: l0n2b, max_grad_data: -0.3801536286554513, sgn switches: 37\n",
      "step 688 learning rate: 0.32605 loss: 0.24106, accuracy: 88.0%, max_grad: 0.44350, max_grad_neuron: l0n2b, max_grad_data: -0.38458861031818503, sgn switches: 23\n",
      "step 689 learning rate: 0.32732 loss: 0.24136, accuracy: 89.0%, max_grad: -0.75169, max_grad_neuron: l0n2b, max_grad_data: -0.37707175074103394, sgn switches: 29\n",
      "step 690 learning rate: 0.31167 loss: 0.24313, accuracy: 88.0%, max_grad: 0.58482, max_grad_neuron: l0n2b, max_grad_data: -0.38291996114413296, sgn switches: 44\n",
      "step 691 learning rate: 0.30413 loss: 0.24045, accuracy: 89.0%, max_grad: -0.15153, max_grad_neuron: l0n2b, max_grad_data: -0.38140468303319874, sgn switches: 38\n",
      "step 692 learning rate: 0.30505 loss: 0.24052, accuracy: 89.0%, max_grad: 0.23991, max_grad_neuron: l0n2b, max_grad_data: -0.38380377060361276, sgn switches: 25\n",
      "step 693 learning rate: 0.30606 loss: 0.24071, accuracy: 89.0%, max_grad: -0.44373, max_grad_neuron: l0n2b, max_grad_data: -0.3793664684684706, sgn switches: 24\n",
      "step 694 learning rate: 0.30683 loss: 0.24152, accuracy: 88.0%, max_grad: 0.54442, max_grad_neuron: l0n2b, max_grad_data: -0.38481065712560913, sgn switches: 33\n",
      "step 695 learning rate: 0.30785 loss: 0.24141, accuracy: 89.0%, max_grad: -0.81530, max_grad_neuron: l0n2b, max_grad_data: -0.3766576777841204, sgn switches: 34\n",
      "step 696 learning rate: 0.27781 loss: 0.24343, accuracy: 88.0%, max_grad: 0.58098, max_grad_neuron: l0n2b, max_grad_data: -0.3824674346520631, sgn switches: 47\n",
      "step 697 learning rate: 0.26327 loss: 0.24032, accuracy: 89.0%, max_grad: 0.05342, max_grad_neuron: l0n2w0, max_grad_data: -0.740366491734799, sgn switches: 31\n",
      "step 698 learning rate: 0.26486 loss: 0.24031, accuracy: 89.0%, max_grad: -0.03371, max_grad_neuron: l0n2w0, max_grad_data: -0.7400293571015331, sgn switches: 16\n",
      "step 699 learning rate: 0.26664 loss: 0.24030, accuracy: 89.0%, max_grad: 0.02494, max_grad_neuron: l0n2b, max_grad_data: -0.3826418408012762, sgn switches: 23\n",
      "step 700 learning rate: 0.26879 loss: 0.24029, accuracy: 89.0%, max_grad: -0.04607, max_grad_neuron: l0n2b, max_grad_data: -0.3821811048212593, sgn switches: 20\n",
      "step 701 learning rate: 0.27103 loss: 0.24029, accuracy: 89.0%, max_grad: 0.08727, max_grad_neuron: l0n2b, max_grad_data: -0.3830538132838578, sgn switches: 22\n",
      "step 702 learning rate: 0.27358 loss: 0.24032, accuracy: 89.0%, max_grad: -0.16413, max_grad_neuron: l0n2b, max_grad_data: -0.3814124932453318, sgn switches: 22\n",
      "step 703 learning rate: 0.27602 loss: 0.24044, accuracy: 89.0%, max_grad: 0.27586, max_grad_neuron: l0n2b, max_grad_data: -0.38417106950853874, sgn switches: 25\n",
      "step 704 learning rate: 0.27873 loss: 0.24075, accuracy: 89.0%, max_grad: -0.54569, max_grad_neuron: l0n2b, max_grad_data: -0.3787141277597956, sgn switches: 28\n",
      "step 705 learning rate: 0.27993 loss: 0.24198, accuracy: 88.0%, max_grad: 0.60382, max_grad_neuron: l0n2b, max_grad_data: -0.38475230925216536, sgn switches: 39\n",
      "step 706 learning rate: 0.28310 loss: 0.24114, accuracy: 89.0%, max_grad: -0.75402, max_grad_neuron: l0n2b, max_grad_data: -0.3772121159357215, sgn switches: 39\n",
      "step 707 learning rate: 0.28277 loss: 0.24308, accuracy: 88.0%, max_grad: 0.61041, max_grad_neuron: l0n2b, max_grad_data: -0.38331619474849504, sgn switches: 44\n",
      "step 708 learning rate: 0.28456 loss: 0.24030, accuracy: 89.0%, max_grad: -0.22246, max_grad_neuron: l0n2b, max_grad_data: -0.3810915978622599, sgn switches: 38\n",
      "step 709 learning rate: 0.28846 loss: 0.24052, accuracy: 89.0%, max_grad: 0.35561, max_grad_neuron: l0n2b, max_grad_data: -0.3846476502872881, sgn switches: 22\n",
      "step 710 learning rate: 0.29244 loss: 0.24100, accuracy: 89.0%, max_grad: -0.70927, max_grad_neuron: l0n2b, max_grad_data: -0.3775549386798993, sgn switches: 28\n",
      "step 711 learning rate: 0.29533 loss: 0.24285, accuracy: 88.0%, max_grad: 0.62160, max_grad_neuron: l0n2b, max_grad_data: -0.3837709609419662, sgn switches: 44\n",
      "step 712 learning rate: 0.29762 loss: 0.24040, accuracy: 89.0%, max_grad: -0.36249, max_grad_neuron: l0n2b, max_grad_data: -0.38014610313222263, sgn switches: 38\n",
      "step 713 learning rate: 0.29794 loss: 0.24099, accuracy: 88.0%, max_grad: 0.51376, max_grad_neuron: l0n2b, max_grad_data: -0.38528365478744414, sgn switches: 25\n",
      "step 714 learning rate: 0.29798 loss: 0.24154, accuracy: 89.0%, max_grad: -0.95711, max_grad_neuron: l0n2b, max_grad_data: -0.3757125711711403, sgn switches: 31\n",
      "step 715 learning rate: 0.25710 loss: 0.24417, accuracy: 88.0%, max_grad: 0.53992, max_grad_neuron: l0n2b, max_grad_data: -0.3811117844806893, sgn switches: 49\n",
      "step 716 learning rate: 0.23740 loss: 0.24053, accuracy: 89.0%, max_grad: 0.37250, max_grad_neuron: l0n2b, max_grad_data: -0.3852092477165883, sgn switches: 20\n",
      "step 717 learning rate: 0.23919 loss: 0.24144, accuracy: 89.0%, max_grad: -0.92929, max_grad_neuron: l0n2b, max_grad_data: -0.3759163417439367, sgn switches: 29\n",
      "step 718 learning rate: 0.22786 loss: 0.24407, accuracy: 88.0%, max_grad: 0.54981, max_grad_neuron: l0n2b, max_grad_data: -0.3814144144267417, sgn switches: 49\n",
      "step 719 learning rate: 0.22279 loss: 0.24041, accuracy: 89.0%, max_grad: 0.31929, max_grad_neuron: l0n2b, max_grad_data: -0.38492664958314404, sgn switches: 20\n",
      "step 720 learning rate: 0.22311 loss: 0.24113, accuracy: 89.0%, max_grad: -0.80725, max_grad_neuron: l0n2b, max_grad_data: -0.37685419920442637, sgn switches: 29\n",
      "step 721 learning rate: 0.21982 loss: 0.24344, accuracy: 88.0%, max_grad: 0.59960, max_grad_neuron: l0n2b, max_grad_data: -0.3828502017873778, sgn switches: 49\n",
      "step 722 learning rate: 0.21849 loss: 0.24012, accuracy: 89.0%, max_grad: 0.07962, max_grad_neuron: l0n2w0, max_grad_data: -0.7408356358876236, sgn switches: 37\n",
      "step 723 learning rate: 0.21876 loss: 0.24011, accuracy: 89.0%, max_grad: -0.05039, max_grad_neuron: l0n2w0, max_grad_data: -0.7403316963511866, sgn switches: 25\n",
      "step 724 learning rate: 0.21936 loss: 0.24011, accuracy: 89.0%, max_grad: -0.07926, max_grad_neuron: l0n2b, max_grad_data: -0.38221834898326645, sgn switches: 19\n",
      "step 725 learning rate: 0.21987 loss: 0.24014, accuracy: 89.0%, max_grad: 0.14455, max_grad_neuron: l0n2b, max_grad_data: -0.38366381375161085, sgn switches: 22\n",
      "step 726 learning rate: 0.22058 loss: 0.24024, accuracy: 89.0%, max_grad: -0.29153, max_grad_neuron: l0n2b, max_grad_data: -0.3807484651275027, sgn switches: 19\n",
      "step 727 learning rate: 0.22087 loss: 0.24069, accuracy: 89.0%, max_grad: 0.45295, max_grad_neuron: l0n2b, max_grad_data: -0.3852779921825252, sgn switches: 26\n",
      "step 728 learning rate: 0.22134 loss: 0.24136, accuracy: 89.0%, max_grad: -0.90983, max_grad_neuron: l0n2b, max_grad_data: -0.3761796584596394, sgn switches: 29\n",
      "step 729 learning rate: 0.21812 loss: 0.24393, accuracy: 88.0%, max_grad: 0.56444, max_grad_neuron: l0n2b, max_grad_data: -0.38182406055857954, sgn switches: 49\n",
      "step 730 learning rate: 0.21803 loss: 0.24027, accuracy: 89.0%, max_grad: 0.25300, max_grad_neuron: l0n2b, max_grad_data: -0.38460703569748733, sgn switches: 21\n",
      "step 731 learning rate: 0.21792 loss: 0.24076, accuracy: 89.0%, max_grad: -0.64121, max_grad_neuron: l0n2b, max_grad_data: -0.3781949812464443, sgn switches: 28\n",
      "step 732 learning rate: 0.21782 loss: 0.24249, accuracy: 88.0%, max_grad: 0.63256, max_grad_neuron: l0n2b, max_grad_data: -0.38452058793497096, sgn switches: 42\n",
      "step 733 learning rate: 0.21805 loss: 0.24063, accuracy: 89.0%, max_grad: -0.57422, max_grad_neuron: l0n2b, max_grad_data: -0.3787783717519375, sgn switches: 36\n",
      "step 734 learning rate: 0.21832 loss: 0.24201, accuracy: 88.0%, max_grad: 0.63201, max_grad_neuron: l0n2b, max_grad_data: -0.3850985051696719, sgn switches: 35\n",
      "step 735 learning rate: 0.21830 loss: 0.24111, accuracy: 89.0%, max_grad: -0.81022, max_grad_neuron: l0n2b, max_grad_data: -0.37699627576065264, sgn switches: 41\n",
      "step 736 learning rate: 0.21771 loss: 0.24338, accuracy: 88.0%, max_grad: 0.60636, max_grad_neuron: l0n2b, max_grad_data: -0.38305991665862144, sgn switches: 48\n",
      "step 737 learning rate: 0.21793 loss: 0.24009, accuracy: 89.0%, max_grad: -0.05917, max_grad_neuron: l0n2b, max_grad_data: -0.38246819641977226, sgn switches: 36\n",
      "step 738 learning rate: 0.21824 loss: 0.24010, accuracy: 89.0%, max_grad: 0.10333, max_grad_neuron: l0n2b, max_grad_data: -0.3835015002750055, sgn switches: 22\n",
      "step 739 learning rate: 0.21863 loss: 0.24015, accuracy: 89.0%, max_grad: -0.19899, max_grad_neuron: l0n2b, max_grad_data: -0.38151158884609415, sgn switches: 22\n",
      "step 740 learning rate: 0.21900 loss: 0.24036, accuracy: 89.0%, max_grad: 0.33653, max_grad_neuron: l0n2b, max_grad_data: -0.384876908070661, sgn switches: 22\n",
      "step 741 learning rate: 0.21938 loss: 0.24087, accuracy: 89.0%, max_grad: -0.70484, max_grad_neuron: l0n2b, max_grad_data: -0.3778284908701838, sgn switches: 28\n",
      "step 742 learning rate: 0.21025 loss: 0.24280, accuracy: 88.0%, max_grad: 0.63155, max_grad_neuron: l0n2b, max_grad_data: -0.38414396036272136, sgn switches: 45\n",
      "step 743 learning rate: 0.20647 loss: 0.24036, accuracy: 89.0%, max_grad: -0.40465, max_grad_neuron: l0n2b, max_grad_data: -0.3800974556252338, sgn switches: 39\n",
      "step 744 learning rate: 0.20731 loss: 0.24113, accuracy: 88.0%, max_grad: 0.55484, max_grad_neuron: l0n2b, max_grad_data: -0.3856458160877559, sgn switches: 28\n",
      "step 745 learning rate: 0.20792 loss: 0.24160, accuracy: 89.0%, max_grad: -1.00751, max_grad_neuron: l0n2b, max_grad_data: -0.37557076564040265, sgn switches: 34\n",
      "step 746 learning rate: 0.20704 loss: 0.24440, accuracy: 88.0%, max_grad: 0.51619, max_grad_neuron: l0n2b, max_grad_data: -0.38073268687962597, sgn switches: 49\n",
      "step 747 learning rate: 0.20786 loss: 0.24081, accuracy: 88.0%, max_grad: 0.47626, max_grad_neuron: l0n2b, max_grad_data: -0.38597156721169634, sgn switches: 18\n",
      "step 748 learning rate: 0.20824 loss: 0.24201, accuracy: 89.0%, max_grad: -1.14448, max_grad_neuron: l0n2b, max_grad_data: -0.3745267187331681, sgn switches: 31\n",
      "step 749 learning rate: 0.20860 loss: 0.24502, accuracy: 88.0%, max_grad: 0.43736, max_grad_neuron: l0n2b, max_grad_data: -0.37890027730098125, sgn switches: 49\n",
      "step 750 learning rate: 0.20568 loss: 0.24208, accuracy: 88.0%, max_grad: 0.62195, max_grad_neuron: l0n2b, max_grad_data: -0.3857417264766802, sgn switches: 9\n",
      "step 751 learning rate: 0.20337 loss: 0.24162, accuracy: 89.0%, max_grad: -1.01287, max_grad_neuron: l0n2b, max_grad_data: -0.3756130195185637, sgn switches: 42\n",
      "step 752 learning rate: 0.20234 loss: 0.24437, accuracy: 88.0%, max_grad: 0.52040, max_grad_neuron: l0n2b, max_grad_data: -0.38081704404703337, sgn switches: 50\n",
      "step 753 learning rate: 0.20290 loss: 0.24075, accuracy: 88.0%, max_grad: 0.47196, max_grad_neuron: l0n2b, max_grad_data: -0.38600864663644985, sgn switches: 20\n",
      "step 754 learning rate: 0.20227 loss: 0.24199, accuracy: 89.0%, max_grad: -1.14208, max_grad_neuron: l0n2b, max_grad_data: -0.37458785626408847, sgn switches: 30\n",
      "step 755 learning rate: 0.20170 loss: 0.24500, accuracy: 88.0%, max_grad: 0.43951, max_grad_neuron: l0n2b, max_grad_data: -0.3789829676379604, sgn switches: 50\n",
      "step 756 learning rate: 0.20238 loss: 0.24204, accuracy: 88.0%, max_grad: 0.62141, max_grad_neuron: l0n2b, max_grad_data: -0.3858184383332009, sgn switches: 8\n",
      "step 757 learning rate: 0.20174 loss: 0.24166, accuracy: 89.0%, max_grad: -1.02962, max_grad_neuron: l0n2b, max_grad_data: -0.37552220284519655, sgn switches: 42\n",
      "step 758 learning rate: 0.20161 loss: 0.24445, accuracy: 88.0%, max_grad: 0.51126, max_grad_neuron: l0n2b, max_grad_data: -0.3806348113399315, sgn switches: 50\n",
      "step 759 learning rate: 0.20215 loss: 0.24088, accuracy: 88.0%, max_grad: 0.50206, max_grad_neuron: l0n2b, max_grad_data: -0.38615747394500854, sgn switches: 17\n",
      "step 760 learning rate: 0.20189 loss: 0.24213, accuracy: 89.0%, max_grad: -1.18772, max_grad_neuron: l0n2b, max_grad_data: -0.37428029270665963, sgn switches: 33\n",
      "step 761 learning rate: 0.20161 loss: 0.24517, accuracy: 88.0%, max_grad: 0.41447, max_grad_neuron: l0n2b, max_grad_data: -0.37842499974519916, sgn switches: 50\n",
      "step 762 learning rate: 0.20231 loss: 0.24248, accuracy: 88.0%, max_grad: 0.62974, max_grad_neuron: l0n2b, max_grad_data: -0.38535213036748545, sgn switches: 7\n",
      "step 763 learning rate: 0.20183 loss: 0.24110, accuracy: 89.0%, max_grad: -0.81466, max_grad_neuron: l0n2b, max_grad_data: -0.3772055259031322, sgn switches: 40\n",
      "step 764 learning rate: 0.20181 loss: 0.24333, accuracy: 88.0%, max_grad: 0.61246, max_grad_neuron: l0n2b, max_grad_data: -0.38333015143143334, sgn switches: 46\n",
      "step 765 learning rate: 0.20196 loss: 0.24006, accuracy: 89.0%, max_grad: -0.08345, max_grad_neuron: l0n2b, max_grad_data: -0.38249567216685343, sgn switches: 42\n",
      "step 766 learning rate: 0.20240 loss: 0.24010, accuracy: 89.0%, max_grad: 0.15160, max_grad_neuron: l0n2b, max_grad_data: -0.3840116596165287, sgn switches: 21\n",
      "step 767 learning rate: 0.20300 loss: 0.24021, accuracy: 89.0%, max_grad: -0.30710, max_grad_neuron: l0n2b, max_grad_data: -0.3809407053116859, sgn switches: 18\n",
      "step 768 learning rate: 0.20329 loss: 0.24070, accuracy: 88.0%, max_grad: 0.47157, max_grad_neuron: l0n2b, max_grad_data: -0.385656414102547, sgn switches: 26\n",
      "step 769 learning rate: 0.20329 loss: 0.24140, accuracy: 89.0%, max_grad: -0.94311, max_grad_neuron: l0n2b, max_grad_data: -0.3762252964744421, sgn switches: 29\n",
      "step 770 learning rate: 0.20174 loss: 0.24407, accuracy: 88.0%, max_grad: 0.55065, max_grad_neuron: l0n2b, max_grad_data: -0.38173181508552007, sgn switches: 49\n",
      "step 771 learning rate: 0.20223 loss: 0.24037, accuracy: 89.0%, max_grad: 0.33738, max_grad_neuron: l0n2b, max_grad_data: -0.3854430204992169, sgn switches: 20\n",
      "step 772 learning rate: 0.20212 loss: 0.24119, accuracy: 89.0%, max_grad: -0.85811, max_grad_neuron: l0n2b, max_grad_data: -0.37686192052749895, sgn switches: 29\n",
      "step 773 learning rate: 0.20183 loss: 0.24366, accuracy: 88.0%, max_grad: 0.58458, max_grad_neuron: l0n2b, max_grad_data: -0.38270769438822744, sgn switches: 49\n",
      "step 774 learning rate: 0.20227 loss: 0.24010, accuracy: 89.0%, max_grad: 0.11816, max_grad_neuron: l0n2b, max_grad_data: -0.3840075064065912, sgn switches: 24\n",
      "step 775 learning rate: 0.20230 loss: 0.24021, accuracy: 89.0%, max_grad: -0.29869, max_grad_neuron: l0n2b, max_grad_data: -0.38102060434893575, sgn switches: 25\n",
      "step 776 learning rate: 0.20264 loss: 0.24071, accuracy: 88.0%, max_grad: 0.46789, max_grad_neuron: l0n2b, max_grad_data: -0.38569953134846263, sgn switches: 29\n",
      "step 777 learning rate: 0.20308 loss: 0.24138, accuracy: 89.0%, max_grad: -0.93718, max_grad_neuron: l0n2b, max_grad_data: -0.3763276986436374, sgn switches: 29\n",
      "step 778 learning rate: 0.20206 loss: 0.24404, accuracy: 88.0%, max_grad: 0.55350, max_grad_neuron: l0n2b, max_grad_data: -0.3818626650111947, sgn switches: 49\n",
      "step 779 learning rate: 0.20258 loss: 0.24033, accuracy: 89.0%, max_grad: 0.32373, max_grad_neuron: l0n2b, max_grad_data: -0.3854236934869515, sgn switches: 21\n",
      "step 780 learning rate: 0.20253 loss: 0.24110, accuracy: 89.0%, max_grad: -0.82569, max_grad_neuron: l0n2b, max_grad_data: -0.37716678809087145, sgn switches: 28\n",
      "step 781 learning rate: 0.20227 loss: 0.24349, accuracy: 88.0%, max_grad: 0.59753, max_grad_neuron: l0n2b, max_grad_data: -0.3831420970373601, sgn switches: 49\n",
      "step 782 learning rate: 0.20274 loss: 0.24005, accuracy: 89.0%, max_grad: 0.08243, max_grad_neuron: l0n2w0, max_grad_data: -0.7415645129603036, sgn switches: 25\n",
      "step 783 learning rate: 0.20284 loss: 0.24004, accuracy: 89.0%, max_grad: -0.06087, max_grad_neuron: l0n2w0, max_grad_data: -0.7409558292883542, sgn switches: 24\n",
      "step 784 learning rate: 0.20335 loss: 0.24006, accuracy: 89.0%, max_grad: 0.10869, max_grad_neuron: l0n2b, max_grad_data: -0.38390397110111885, sgn switches: 25\n",
      "step 785 learning rate: 0.20393 loss: 0.24012, accuracy: 89.0%, max_grad: -0.22704, max_grad_neuron: l0n2b, max_grad_data: -0.38163361669049645, sgn switches: 25\n",
      "step 786 learning rate: 0.20426 loss: 0.24041, accuracy: 89.0%, max_grad: 0.38083, max_grad_neuron: l0n2b, max_grad_data: -0.38544188322980893, sgn switches: 29\n",
      "step 787 learning rate: 0.20487 loss: 0.24102, accuracy: 89.0%, max_grad: -0.79891, max_grad_neuron: l0n2b, max_grad_data: -0.37745280322887514, sgn switches: 29\n",
      "step 788 learning rate: 0.20329 loss: 0.24330, accuracy: 88.0%, max_grad: 0.61148, max_grad_neuron: l0n2b, max_grad_data: -0.38356759705569804, sgn switches: 47\n",
      "step 789 learning rate: 0.20365 loss: 0.24005, accuracy: 89.0%, max_grad: -0.09489, max_grad_neuron: l0n2b, max_grad_data: -0.38261874014100655, sgn switches: 38\n",
      "step 790 learning rate: 0.20410 loss: 0.24008, accuracy: 89.0%, max_grad: 0.16692, max_grad_neuron: l0n2b, max_grad_data: -0.3842879310031955, sgn switches: 25\n",
      "step 791 learning rate: 0.20485 loss: 0.24021, accuracy: 89.0%, max_grad: -0.33562, max_grad_neuron: l0n2b, max_grad_data: -0.3809317237772902, sgn switches: 19\n",
      "step 792 learning rate: 0.20525 loss: 0.24079, accuracy: 88.0%, max_grad: 0.50109, max_grad_neuron: l0n2b, max_grad_data: -0.38594263217219066, sgn switches: 27\n",
      "step 793 learning rate: 0.20588 loss: 0.24148, accuracy: 89.0%, max_grad: -0.98384, max_grad_neuron: l0n2b, max_grad_data: -0.3761041997921536, sgn switches: 30\n",
      "step 794 learning rate: 0.19634 loss: 0.24425, accuracy: 88.0%, max_grad: 0.53141, max_grad_neuron: l0n2b, max_grad_data: -0.38141833369310923, sgn switches: 50\n",
      "step 795 learning rate: 0.19292 loss: 0.24058, accuracy: 89.0%, max_grad: 0.42911, max_grad_neuron: l0n2b, max_grad_data: -0.38613859785042315, sgn switches: 21\n",
      "step 796 learning rate: 0.19349 loss: 0.24172, accuracy: 89.0%, max_grad: -1.06941, max_grad_neuron: l0n2b, max_grad_data: -0.3754444643279422, sgn switches: 29\n",
      "step 797 learning rate: 0.19129 loss: 0.24468, accuracy: 88.0%, max_grad: 0.48037, max_grad_neuron: l0n2b, max_grad_data: -0.38024813203828406, sgn switches: 50\n",
      "step 798 learning rate: 0.19243 loss: 0.24132, accuracy: 88.0%, max_grad: 0.57214, max_grad_neuron: l0n2b, max_grad_data: -0.3865416972842952, sgn switches: 15\n",
      "step 799 learning rate: 0.19132 loss: 0.24219, accuracy: 89.0%, max_grad: -1.21949, max_grad_neuron: l0n2b, max_grad_data: -0.3743468162281251, sgn switches: 35\n",
      "step 800 learning rate: 0.19165 loss: 0.24526, accuracy: 88.0%, max_grad: 0.40055, max_grad_neuron: l0n2b, max_grad_data: -0.3783522789192862, sgn switches: 49\n",
      "step 801 learning rate: 0.19219 loss: 0.24272, accuracy: 88.0%, max_grad: 0.63082, max_grad_neuron: l0n2b, max_grad_data: -0.3852912823358254, sgn switches: 6\n",
      "step 802 learning rate: 0.19197 loss: 0.24074, accuracy: 89.0%, max_grad: -0.67165, max_grad_neuron: l0n2b, max_grad_data: -0.37857481815196714, sgn switches: 39\n",
      "step 803 learning rate: 0.19262 loss: 0.24249, accuracy: 88.0%, max_grad: 0.64448, max_grad_neuron: l0n2b, max_grad_data: -0.3850196019247903, sgn switches: 39\n",
      "step 804 learning rate: 0.19305 loss: 0.24055, accuracy: 89.0%, max_grad: -0.57579, max_grad_neuron: l0n2b, max_grad_data: -0.37926174922966854, sgn switches: 45\n",
      "step 805 learning rate: 0.19394 loss: 0.24201, accuracy: 88.0%, max_grad: 0.63554, max_grad_neuron: l0n2b, max_grad_data: -0.3856171793594141, sgn switches: 42\n",
      "step 806 learning rate: 0.19491 loss: 0.24101, accuracy: 89.0%, max_grad: -0.80093, max_grad_neuron: l0n2b, max_grad_data: -0.3776078731793148, sgn switches: 42\n",
      "step 807 learning rate: 0.19545 loss: 0.24326, accuracy: 88.0%, max_grad: 0.61617, max_grad_neuron: l0n2b, max_grad_data: -0.3837695660904345, sgn switches: 48\n",
      "step 808 learning rate: 0.19661 loss: 0.24003, accuracy: 89.0%, max_grad: -0.11549, max_grad_neuron: l0n2b, max_grad_data: -0.3826146860580889, sgn switches: 40\n",
      "step 809 learning rate: 0.19809 loss: 0.24009, accuracy: 89.0%, max_grad: 0.20529, max_grad_neuron: l0n2b, max_grad_data: -0.38466757728102013, sgn switches: 24\n",
      "step 810 learning rate: 0.19976 loss: 0.24030, accuracy: 89.0%, max_grad: -0.42394, max_grad_neuron: l0n2b, max_grad_data: -0.3804281638637271, sgn switches: 22\n",
      "step 811 learning rate: 0.20122 loss: 0.24119, accuracy: 88.0%, max_grad: 0.57344, max_grad_neuron: l0n2b, max_grad_data: -0.38616254444576315, sgn switches: 31\n",
      "step 812 learning rate: 0.20280 loss: 0.24155, accuracy: 89.0%, max_grad: -1.01556, max_grad_neuron: l0n2b, max_grad_data: -0.3760069304023409, sgn switches: 34\n",
      "step 813 learning rate: 0.20187 loss: 0.24439, accuracy: 88.0%, max_grad: 0.51646, max_grad_neuron: l0n2b, max_grad_data: -0.3811714931449546, sgn switches: 49\n",
      "step 814 learning rate: 0.20228 loss: 0.24077, accuracy: 88.0%, max_grad: 0.48781, max_grad_neuron: l0n2b, max_grad_data: -0.38653738581591873, sgn switches: 17\n",
      "step 815 learning rate: 0.20207 loss: 0.24204, accuracy: 89.0%, max_grad: -1.17806, max_grad_neuron: l0n2b, max_grad_data: -0.3747568291862369, sgn switches: 32\n",
      "step 816 learning rate: 0.20183 loss: 0.24511, accuracy: 88.0%, max_grad: 0.42072, max_grad_neuron: l0n2b, max_grad_data: -0.37896402143085545, sgn switches: 49\n",
      "step 817 learning rate: 0.20253 loss: 0.24235, accuracy: 88.0%, max_grad: 0.63277, max_grad_neuron: l0n2b, max_grad_data: -0.3859245378871971, sgn switches: 8\n",
      "step 818 learning rate: 0.20214 loss: 0.24120, accuracy: 89.0%, max_grad: -0.88137, max_grad_neuron: l0n2b, max_grad_data: -0.37711085129039934, sgn switches: 38\n",
      "step 819 learning rate: 0.20212 loss: 0.24366, accuracy: 88.0%, max_grad: 0.58993, max_grad_neuron: l0n2b, max_grad_data: -0.3830101167776528, sgn switches: 46\n",
      "step 820 learning rate: 0.20259 loss: 0.24003, accuracy: 89.0%, max_grad: 0.12920, max_grad_neuron: l0n2b, max_grad_data: -0.3844313520116134, sgn switches: 24\n",
      "step 821 learning rate: 0.20245 loss: 0.24017, accuracy: 89.0%, max_grad: -0.31925, max_grad_neuron: l0n2b, max_grad_data: -0.3812388042265428, sgn switches: 25\n",
      "step 822 learning rate: 0.20280 loss: 0.24073, accuracy: 88.0%, max_grad: 0.48951, max_grad_neuron: l0n2b, max_grad_data: -0.3861338949259949, sgn switches: 29\n",
      "step 823 learning rate: 0.20326 loss: 0.24143, accuracy: 89.0%, max_grad: -0.97511, max_grad_neuron: l0n2b, max_grad_data: -0.3763828444687785, sgn switches: 29\n",
      "step 824 learning rate: 0.20227 loss: 0.24420, accuracy: 88.0%, max_grad: 0.53697, max_grad_neuron: l0n2b, max_grad_data: -0.3817525234257291, sgn switches: 49\n",
      "step 825 learning rate: 0.20282 loss: 0.24049, accuracy: 89.0%, max_grad: 0.41079, max_grad_neuron: l0n2b, max_grad_data: -0.38627121747056214, sgn switches: 20\n",
      "step 826 learning rate: 0.20276 loss: 0.24159, accuracy: 89.0%, max_grad: -1.03587, max_grad_neuron: l0n2b, max_grad_data: -0.37591256542107077, sgn switches: 29\n",
      "step 827 learning rate: 0.20254 loss: 0.24452, accuracy: 88.0%, max_grad: 0.49978, max_grad_neuron: l0n2b, max_grad_data: -0.38091035555345054, sgn switches: 49\n",
      "step 828 learning rate: 0.20319 loss: 0.24100, accuracy: 88.0%, max_grad: 0.53069, max_grad_neuron: l0n2b, max_grad_data: -0.3867479685496982, sgn switches: 15\n",
      "step 829 learning rate: 0.20301 loss: 0.24217, accuracy: 89.0%, max_grad: -1.22359, max_grad_neuron: l0n2b, max_grad_data: -0.374512103600397, sgn switches: 34\n",
      "step 830 learning rate: 0.20290 loss: 0.24527, accuracy: 88.0%, max_grad: 0.39654, max_grad_neuron: l0n2b, max_grad_data: -0.3784775518317557, sgn switches: 49\n",
      "step 831 learning rate: 0.20375 loss: 0.24278, accuracy: 88.0%, max_grad: 0.62959, max_grad_neuron: l0n2b, max_grad_data: -0.3854029912254472, sgn switches: 5\n",
      "step 832 learning rate: 0.20348 loss: 0.24063, accuracy: 89.0%, max_grad: -0.62938, max_grad_neuron: l0n2b, max_grad_data: -0.3791091719941383, sgn switches: 38\n",
      "step 833 learning rate: 0.20391 loss: 0.24223, accuracy: 88.0%, max_grad: 0.64664, max_grad_neuron: l0n2b, max_grad_data: -0.38557553237813685, sgn switches: 35\n",
      "step 834 learning rate: 0.20393 loss: 0.24078, accuracy: 89.0%, max_grad: -0.71125, max_grad_neuron: l0n2b, max_grad_data: -0.3784630795015016, sgn switches: 41\n",
      "step 835 learning rate: 0.20415 loss: 0.24276, accuracy: 88.0%, max_grad: 0.63710, max_grad_neuron: l0n2b, max_grad_data: -0.3848340739822803, sgn switches: 44\n",
      "step 836 learning rate: 0.20460 loss: 0.24026, accuracy: 89.0%, max_grad: -0.40890, max_grad_neuron: l0n2b, max_grad_data: -0.3807450605861491, sgn switches: 38\n",
      "step 837 learning rate: 0.20525 loss: 0.24107, accuracy: 88.0%, max_grad: 0.56359, max_grad_neuron: l0n2b, max_grad_data: -0.3863809764284776, sgn switches: 28\n",
      "step 838 learning rate: 0.20565 loss: 0.24158, accuracy: 89.0%, max_grad: -1.03398, max_grad_neuron: l0n2b, max_grad_data: -0.37604119507204303, sgn switches: 34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\demo2.ipynb Zelle 10\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m last_max_grad_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(size):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     total_loss, acc \u001b[39m=\u001b[39m loss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mif\u001b[39;00m acc \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy reached.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\demo2.ipynb Zelle 10\u001b[0m in \u001b[0;36mloss\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m inputs \u001b[39m=\u001b[39m [\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(Value, \u001b[39mmap\u001b[39m(\u001b[39mfloat\u001b[39m,xrow))) \u001b[39mfor\u001b[39;00m xrow \u001b[39min\u001b[39;00m Xb]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# forward the model to get scores\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(model, inputs))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# svm \"max-margin\" loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projekte/GitHub/micrograd/demo2.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m losses \u001b[39m=\u001b[39m [(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39m-\u001b[39myi\u001b[39m*\u001b[39mscorei)\u001b[39m.\u001b[39mrelu() \u001b[39mfor\u001b[39;00m yi, scorei \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(yb, scores)]\n",
      "File \u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\micrograd\\nn.py:76\u001b[0m, in \u001b[0;36mMLP.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     75\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> 76\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\micrograd\\nn.py:59\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 59\u001b[0m     out \u001b[39m=\u001b[39m [n(x) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons]\n\u001b[0;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m out[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\micrograd\\nn.py:59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 59\u001b[0m     out \u001b[39m=\u001b[39m [n(x) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons]\n\u001b[0;32m     60\u001b[0m     \u001b[39mreturn\u001b[39;00m out[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\micrograd\\nn.py:37\u001b[0m, in \u001b[0;36mNeuron.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m act2 \u001b[39m=\u001b[39m Value(\u001b[39m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39m\"\"\"for wi,xi in zip(self.w,x):\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m    act1 = act1 + wi*xi\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    act2 = act2 + (wi-xi)**2\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mreturn (act1*b1-act2*b2).tanh()\"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m act \u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m((wi\u001b[39m*\u001b[39;49mxi \u001b[39mfor\u001b[39;49;00m wi,xi \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw, x)), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb)\n\u001b[0;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m act\u001b[39m.\u001b[39mtanh() \u001b[39m*\u001b[39m b1 \u001b[39m+\u001b[39m act \u001b[39m*\u001b[39m b2\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mreturn act.relu() if self.nonlin else act\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\micrograd\\nn.py:37\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m act2 \u001b[39m=\u001b[39m Value(\u001b[39m0\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[39m\"\"\"for wi,xi in zip(self.w,x):\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m    act1 = act1 + wi*xi\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    act2 = act2 + (wi-xi)**2\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mreturn (act1*b1-act2*b2).tanh()\"\"\"\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m act \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m((wi\u001b[39m*\u001b[39;49mxi \u001b[39mfor\u001b[39;00m wi,xi \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw, x)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb)\n\u001b[0;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m act\u001b[39m.\u001b[39mtanh() \u001b[39m*\u001b[39m b1 \u001b[39m+\u001b[39m act \u001b[39m*\u001b[39m b2\n\u001b[0;32m     39\u001b[0m \u001b[39m\"\"\"act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mreturn act.relu() if self.nonlin else act\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\micrograd\\engine.py:30\u001b[0m, in \u001b[0;36mValue.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__mul__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m     29\u001b[0m     other \u001b[39m=\u001b[39m other \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Value) \u001b[39melse\u001b[39;00m Value(other)\n\u001b[1;32m---> 30\u001b[0m     out \u001b[39m=\u001b[39m Value(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata \u001b[39m*\u001b[39;49m other\u001b[39m.\u001b[39;49mdata, (\u001b[39mself\u001b[39;49m, other), \u001b[39m'\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     32\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m():\n\u001b[0;32m     33\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mdata \u001b[39m*\u001b[39m out\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[1;32mc:\\Projekte\\GitHub\\micrograd\\micrograd\\engine.py:8\u001b[0m, in \u001b[0;36mValue.__init__\u001b[1;34m(self, data, _children, _op)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data, _children\u001b[39m=\u001b[39m(), _op\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValue\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata \u001b[39m=\u001b[39m data\n\u001b[0;32m      9\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_grad \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimization\n",
    "from cmath import sqrt\n",
    "\n",
    "def sgn(value:float):\n",
    "    if value >= 0:\n",
    "        return 1.   \n",
    "    return -1.\n",
    "\n",
    "model.init_learning_rate()\n",
    "\n",
    "size = 5000\n",
    "last_max_grad_value = None\n",
    "for k in range(size):\n",
    "    \n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "\n",
    "    if acc >= 1.0:\n",
    "        print(\"Accuracy reached.\")\n",
    "        break\n",
    "    \n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "    \n",
    "    # update (sgd)\n",
    "    #learning_rate = 1.0 - 0.8*k/size\n",
    "    #learning_rate = 0.001\n",
    "    #learning_rate = 5.*total_loss.data\n",
    "    max_grad = 0\n",
    "    max_grad_no_abs = 0\n",
    "    max_grad_value = None\n",
    "\n",
    "    parameters = model.parameters()\n",
    "    for p in parameters:\n",
    "        abs_grad = abs(p.grad)\n",
    "        if abs_grad > max_grad:\n",
    "            max_grad = abs_grad\n",
    "            max_grad_no_abs = p.grad\n",
    "            max_grad_value = p\n",
    "\n",
    "    \"\"\"if sgn(max_grad_value.grad) != sgn(max_grad_value.last_grad):\n",
    "        learning_rate *= 0.99\n",
    "    else:\n",
    "        learning_rate /= 0.99\"\"\"\n",
    "    \n",
    "    last_max_grad_value = max_grad_value\n",
    "\n",
    "    count_sgn_switches = 0\n",
    "\n",
    "    learning_rate = 0.0\n",
    "    \n",
    "    for p in parameters:\n",
    "        switched = 1 if sgn(p.grad) != sgn(p.last_grad) else 0\n",
    "        count_sgn_switches += switched\n",
    "        if switched == 1:\n",
    "            p.learning_rate = max(min(0.75,p.learning_rate * 0.5),0.01)\n",
    "        else:\n",
    "            #step_to_do = (0 - p.grad)\n",
    "            #step_done = (p.grad - p.last_grad)\n",
    "            p.learning_rate = min(p.learning_rate * 1.1,1.0)\n",
    "            #p.learning_rate = min(p.learning_rate * abs(step_to_do / step_done),10)\n",
    "\n",
    "\n",
    "        #p.learning_rate = min(p.learning_rate * abs(step_to_do / step_done),10)\n",
    "        learning_rate += p.learning_rate / len(parameters)\n",
    "\n",
    "\n",
    "\n",
    "        update_value = p.learning_rate * p.grad\n",
    "\n",
    "\n",
    "\n",
    "        p.last_grad = p.grad\n",
    "        p.data -= update_value\n",
    "\n",
    "    if max_grad < 0.0001:\n",
    "        print(\"Plateau reached.\")\n",
    "        break\n",
    "   \n",
    "    if k % 1 == 0:\n",
    "        print(f\"step {k} learning rate: {learning_rate:.5f} loss: {total_loss.data:.5f}, accuracy: {acc*100}%, max_grad: {max_grad_no_abs:.5f}, max_grad_neuron: {max_grad_value._op}, max_grad_data: {max_grad_value.data}, sgn switches: {count_sgn_switches}\")\n",
    "\n",
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizeBoundary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ed094bc584b0357ba1496b5fd74ffa57926b2f91385d6a0a942d0ad57564af6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
